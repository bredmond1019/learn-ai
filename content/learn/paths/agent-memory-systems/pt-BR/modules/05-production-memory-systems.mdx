---
title: "Sistemas de Memória em Produção"
description: "Implante sistemas de memória com MongoDB em escala"
duration: "150 minutos"
difficulty: "intermediate"
objectives:
  - "Implantar sistemas de memória com MongoDB Atlas"
  - "Implementar padrões básicos de segurança e desempenho"
  - "Construir sistemas de monitoramento e manutenção"
  - "Escalar sistemas de memória para cargas de trabalho de produção"
tags:
  - "produção"
  - "mongodb"
  - "escalonamento"
  - "implantação"
lastUpdated: "2025-01-08"
author: "Brandon Redmond"
---

# Sistemas de Memória em Produção

Bem-vindo ao módulo final! Vamos pegar tudo que aprendemos e implantar usando o MongoDB como nosso provedor de memória. Como Richmond Alake disse, "MongoDB é o provedor de memória para sistemas agênticos."

## Por que MongoDB para Memória de Agentes?

A equipe de Richmond escolheu o MongoDB porque:

<Callout type="insight" title="MongoDB como Provedor de Memória">
"O modelo de documento flexível pode se adaptar a qualquer estrutura de memória que você precise, fornecendo todas as capacidades de recuperação: grafo, vetor, texto, geoespacial e consulta em um único banco de dados." - Richmond Alake
</Callout>

Vamos ver como construir sistemas de memória prontos para produção.

## Conexão Básica com MongoDB

Comece com uma conexão simples e pronta para produção:

<CodeExample language="javascript" title="Conexão MongoDB">
const { MongoClient } = require('mongodb');

class ProductionMemoryDB {
  constructor(connectionString) {
    this.client = new MongoClient(connectionString, {
      maxPoolSize: 50,
      wtimeoutMS: 2500,
      useNewUrlParser: true
    });
    this.db = null;
  }
  
  async connect() {
    await this.client.connect();
    this.db = this.client.db('agent-memory');
    
    // Ensure indexes for performance
    await this.createIndexes();
    
    console.log('Connected to MongoDB Atlas');
  }
  
  async createIndexes() {
    const memories = this.db.collection('memories');
    
    // Basic indexes for common queries
    await memories.createIndex({ userId: 1, createdAt: -1 });
    await memories.createIndex({ type: 1, importance: -1 });
    await memories.createIndex({ tags: 1 });
    
    // Text search index
    await memories.createIndex({ content: 'text', tags: 'text' });
  }
}
</CodeExample>

## Sistema de Memória Simples para Produção

Construa um sistema de memória pronto para produção:

<CodeExample language="javascript" title="Gerenciador de Memória de Produção">
class ProductionMemorySystem {
  constructor(db) {
    this.db = db;
    this.cache = new Map(); // Simple in-memory cache
  }
  
  // Store memory with validation
  async storeMemory(userId, content, type = 'general') {
    // Basic validation
    if (!userId || !content) {
      throw new Error('userId and content are required');
    }
    
    if (content.length > 10000) {
      throw new Error('Content too large (max 10000 characters)');
    }
    
    const memory = {
      userId,
      content: content.trim(),
      type,
      importance: this.calculateImportance(content),
      tags: this.extractTags(content),
      createdAt: new Date(),
      lastAccessed: new Date(),
      accessCount: 1
    };
    
    const result = await this.db.collection('memories').insertOne(memory);
    
    // Clear user cache when new memory added
    this.clearUserCache(userId);
    
    return result.insertedId;
  }
}
</CodeExample>

Adicionar recuperação com cache:

<CodeExample language="javascript" title="Recuperação de Memória com Cache">
  // Retrieve memories with caching
  async getMemories(userId, query, limit = 10) {
    const cacheKey = `${userId}:${query}:${limit}`;
    
    // Check cache first
    if (this.cache.has(cacheKey)) {
      const cached = this.cache.get(cacheKey);
      if (Date.now() - cached.timestamp < 300000) { // 5 minutes
        return cached.data;
      }
    }
    
    // Query database
    const memories = await this.db.collection('memories').find({
      userId: userId,
      $text: { $search: query }
    })
    .sort({ importance: -1, createdAt: -1 })
    .limit(limit)
    .toArray();
    
    // Cache results
    this.cache.set(cacheKey, {
      data: memories,
      timestamp: Date.now()
    });
    
    // Update access counts (async, don't wait)
    this.updateAccessCounts(memories.map(m => m._id));
    
    return memories;
  }
  
  async updateAccessCounts(memoryIds) {
    try {
      await this.db.collection('memories').updateMany(
        { _id: { $in: memoryIds } },
        { 
          $inc: { accessCount: 1 },
          $set: { lastAccessed: new Date() }
        }
      );
    } catch (error) {
      console.error('Failed to update access counts:', error);
      // Don't throw - this is non-critical
    }
  }
</CodeExample>

## Padrões Simples de Escalonamento

Lidar com múltiplos usuários e alto throughput:

<CodeExample language="javascript" title="Processamento em Lote">
class BatchMemoryProcessor {
  constructor(memorySystem) {
    this.memorySystem = memorySystem;
    this.batchQueue = [];
    this.batchSize = 100;
    this.batchTimeout = 5000; // 5 seconds
    
    // Process batches periodically
    setInterval(() => this.processBatch(), this.batchTimeout);
  }
  
  // Queue memory for batch processing
  queueMemory(userId, content, type) {
    return new Promise((resolve, reject) => {
      this.batchQueue.push({
        userId,
        content,
        type,
        resolve,
        reject,
        timestamp: Date.now()
      });
      
      // Process immediately if batch is full
      if (this.batchQueue.length >= this.batchSize) {
        this.processBatch();
      }
    });
  }
  
  async processBatch() {
    if (this.batchQueue.length === 0) return;
    
    const batch = this.batchQueue.splice(0, this.batchSize);
    
    try {
      // Process all memories in batch
      const operations = batch.map(item => ({
        insertOne: {
          document: {
            userId: item.userId,
            content: item.content,
            type: item.type,
            createdAt: new Date(),
            importance: this.memorySystem.calculateImportance(item.content)
          }
        }
      }));
      
      const result = await this.memorySystem.db.collection('memories').bulkWrite(operations);
      
      // Resolve all promises
      batch.forEach((item, index) => {
        item.resolve(result.insertedIds[index]);
      });
      
    } catch (error) {
      // Reject all promises
      batch.forEach(item => item.reject(error));
    }
  }
}
</CodeExample>

## Padrões Básicos de Segurança

Implemente segurança simples mas eficaz:

<CodeExample language="javascript" title="Segurança Básica">
class SecureMemorySystem {
  constructor(db) {
    this.db = db;
    this.rateLimiter = new Map(); // Simple rate limiting
  }
  
  // Basic rate limiting
  checkRateLimit(userId, maxRequests = 100, windowMs = 60000) {
    const now = Date.now();
    const windowStart = now - windowMs;
    
    if (!this.rateLimiter.has(userId)) {
      this.rateLimiter.set(userId, []);
    }
    
    const userRequests = this.rateLimiter.get(userId);
    
    // Remove old requests
    const recentRequests = userRequests.filter(time => time > windowStart);
    
    if (recentRequests.length >= maxRequests) {
      throw new Error('Rate limit exceeded');
    }
    
    // Add current request
    recentRequests.push(now);
    this.rateLimiter.set(userId, recentRequests);
  }
  
  // Input sanitization
  sanitizeInput(content) {
    if (typeof content !== 'string') {
      throw new Error('Content must be a string');
    }
    
    // Remove potential script tags and SQL injection attempts
    const sanitized = content
      .replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, '')
      .replace(/['"`;]/g, '')
      .trim();
    
    if (sanitized.length === 0) {
      throw new Error('Content cannot be empty after sanitization');
    }
    
    return sanitized;
  }
}
</CodeExample>

## Monitoramento Simples

Monitore a saúde do seu sistema de memória:

<CodeExample language="javascript" title="Monitoramento Básico">
class MemorySystemMonitor {
  constructor(memorySystem) {
    this.memorySystem = memorySystem;
    this.metrics = {
      memoriesStored: 0,
      memoriesRetrieved: 0,
      errors: 0,
      responseTimeSum: 0,
      responseTimeCount: 0
    };
  }
  
  // Track operation metrics
  trackOperation(operation, duration, success = true) {
    if (operation === 'store') {
      this.metrics.memoriesStored++;
    } else if (operation === 'retrieve') {
      this.metrics.memoriesRetrieved++;
    }
    
    if (!success) {
      this.metrics.errors++;
    }
    
    this.metrics.responseTimeSum += duration;
    this.metrics.responseTimeCount++;
  }
  
  // Get current metrics
  getMetrics() {
    const avgResponseTime = this.metrics.responseTimeCount > 0 
      ? this.metrics.responseTimeSum / this.metrics.responseTimeCount 
      : 0;
    
    return {
      ...this.metrics,
      averageResponseTime: Math.round(avgResponseTime),
      errorRate: this.metrics.responseTimeCount > 0 
        ? this.metrics.errors / this.metrics.responseTimeCount 
        : 0
    };
  }
  
  // Check system health
  async checkHealth() {
    try {
      const start = Date.now();
      
      // Test database connection
      await this.memorySystem.db.admin().ping();
      
      // Test collection access
      await this.memorySystem.db.collection('memories').countDocuments({}, { limit: 1 });
      
      const responseTime = Date.now() - start;
      
      return {
        status: 'healthy',
        responseTime,
        timestamp: new Date()
      };
    } catch (error) {
      return {
        status: 'unhealthy',
        error: error.message,
        timestamp: new Date()
      };
    }
  }
}
</CodeExample>

## Tarefas Simples de Manutenção

Automatize a manutenção do sistema de memória:

<CodeExample language="javascript" title="Manutenção Automatizada">
class MemoryMaintenance {
  constructor(memorySystem) {
    this.memorySystem = memorySystem;
    
    // Schedule maintenance tasks
    this.scheduleMaintenanceTasks();
  }
  
  scheduleMaintenanceTasks() {
    // Run daily cleanup at 2 AM
    setInterval(() => {
      this.runDailyMaintenance();
    }, 24 * 60 * 60 * 1000); // 24 hours
    
    // Run hourly cache cleanup
    setInterval(() => {
      this.cleanupCache();
    }, 60 * 60 * 1000); // 1 hour
  }
  
  async runDailyMaintenance() {
    console.log('Starting daily maintenance...');
    
    try {
      // 1. Clean up old, unimportant memories
      const cleanupResult = await this.memorySystem.db.collection('memories').deleteMany({
        importance: { $lt: 0.1 },
        createdAt: { $lt: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000) } // 30 days old
      });
      
      // 2. Update memory importance based on access patterns
      await this.updateMemoryImportance();
      
      // 3. Optimize database indexes
      await this.optimizeIndexes();
      
      console.log(`Daily maintenance complete: ${cleanupResult.deletedCount} memories cleaned`);
      
    } catch (error) {
      console.error('Daily maintenance failed:', error);
    }
  }
  
  async updateMemoryImportance() {
    const memories = await this.memorySystem.db.collection('memories').find({
      lastAccessed: { $gte: new Date(Date.now() - 7 * 24 * 60 * 60 * 1000) } // Last 7 days
    }).toArray();
    
    for (const memory of memories) {
      const newImportance = this.calculateUpdatedImportance(memory);
      
      await this.memorySystem.db.collection('memories').updateOne(
        { _id: memory._id },
        { $set: { importance: newImportance } }
      );
    }
  }
  
  calculateUpdatedImportance(memory) {
    const daysSinceCreated = (Date.now() - memory.createdAt) / (1000 * 60 * 60 * 24);
    const daysSinceAccessed = (Date.now() - memory.lastAccessed) / (1000 * 60 * 60 * 24);
    
    // Base importance decays over time
    let importance = memory.importance * Math.pow(0.95, daysSinceCreated);
    
    // But frequent access increases importance
    if (memory.accessCount > 5) {
      importance *= 1.2;
    }
    
    // Recent access prevents decay
    if (daysSinceAccessed < 1) {
      importance *= 1.1;
    }
    
    return Math.min(Math.max(importance, 0), 1);
  }
}
</CodeExample>

## Juntando Tudo

Sistema completo de produção:

<CodeExample language="javascript" title="Sistema Completo de Produção">
class ProductionAgentMemory {
  constructor(connectionString) {
    this.db = new ProductionMemoryDB(connectionString);
    this.memorySystem = null;
    this.batchProcessor = null;
    this.monitor = null;
    this.maintenance = null;
  }
  
  async initialize() {
    // Connect to database
    await this.db.connect();
    
    // Initialize components
    this.memorySystem = new ProductionMemorySystem(this.db.db);
    this.batchProcessor = new BatchMemoryProcessor(this.memorySystem);
    this.monitor = new MemorySystemMonitor(this.memorySystem);
    this.maintenance = new MemoryMaintenance(this.memorySystem);
    
    console.log('Production memory system initialized');
  }
  
  // Main API for agents
  async storeMemory(userId, content, type = 'general') {
    const start = Date.now();
    
    try {
      // Security checks
      const secureSystem = new SecureMemorySystem(this.db.db);
      secureSystem.checkRateLimit(userId);
      const sanitizedContent = secureSystem.sanitizeInput(content);
      
      // Store memory
      const memoryId = await this.memorySystem.storeMemory(userId, sanitizedContent, type);
      
      // Track metrics
      this.monitor.trackOperation('store', Date.now() - start, true);
      
      return memoryId;
    } catch (error) {
      this.monitor.trackOperation('store', Date.now() - start, false);
      throw error;
    }
  }
  
  async getMemories(userId, query, limit = 10) {
    const start = Date.now();
    
    try {
      const memories = await this.memorySystem.getMemories(userId, query, limit);
      
      this.monitor.trackOperation('retrieve', Date.now() - start, true);
      
      return memories;
    } catch (error) {
      this.monitor.trackOperation('retrieve', Date.now() - start, false);
      throw error;
    }
  }
  
  // Health check endpoint
  async healthCheck() {
    return await this.monitor.checkHealth();
  }
  
  // Metrics endpoint
  getMetrics() {
    return this.monitor.getMetrics();
  }
}
</CodeExample>

## Exemplo de Implantação

Exemplo de configuração de implantação:

<CodeExample language="javascript" title="Configuração de Implantação">
// app.js - Express server example
const express = require('express');
const ProductionAgentMemory = require('./ProductionAgentMemory');

const app = express();
app.use(express.json({ limit: '10mb' }));

// Initialize memory system
const memorySystem = new ProductionAgentMemory(process.env.MONGODB_URI);

app.listen(3000, async () => {
  await memorySystem.initialize();
  console.log('Memory service running on port 3000');
});

// API endpoints
app.post('/memories', async (req, res) => {
  try {
    const { userId, content, type } = req.body;
    const memoryId = await memorySystem.storeMemory(userId, content, type);
    res.json({ success: true, memoryId });
  } catch (error) {
    res.status(400).json({ error: error.message });
  }
});

app.get('/memories/:userId', async (req, res) => {
  try {
    const { userId } = req.params;
    const { query, limit } = req.query;
    const memories = await memorySystem.getMemories(userId, query, parseInt(limit) || 10);
    res.json({ memories });
  } catch (error) {
    res.status(400).json({ error: error.message });
  }
});

app.get('/health', async (req, res) => {
  const health = await memorySystem.healthCheck();
  res.json(health);
});

app.get('/metrics', (req, res) => {
  const metrics = memorySystem.getMetrics();
  res.json(metrics);
});
</CodeExample>

## Configuração de Ambiente

<CodeExample language="bash" title="Variáveis de Ambiente">
# .env file for production
MONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/agent-memory
NODE_ENV=production
PORT=3000

# Optional: Enable additional features
ENABLE_VECTOR_SEARCH=true
ENABLE_DETAILED_LOGGING=false
CACHE_TTL_SECONDS=300

# Security
API_KEY_REQUIRED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=100
</CodeExample>

## Verificação de Conhecimento

<Quiz>
  <Question
    question="Por que a equipe de Richmond escolheu o MongoDB para memória de agentes?"
    options={[
      "É o banco de dados mais rápido",
      "É a opção mais barata",
      "O modelo de documento flexível se adapta a qualquer estrutura de memória",
      "Tem a melhor interface de usuário"
    ]}
    correct={2}
    explanation="Richmond enfatizou que o modelo de documento flexível do MongoDB pode se adaptar a qualquer estrutura de memória, fornecendo todas as capacidades de recuperação necessárias em um único banco de dados."
  />
  
  <Question
    question="Qual é o principal benefício do processamento em lote para operações de memória?"
    options={[
      "Melhora a precisão",
      "Reduz a carga do banco de dados e melhora o throughput",
      "Fornece melhor segurança",
      "Usa menos memória"
    ]}
    correct={1}
    explanation="O processamento em lote reduz a carga do banco de dados combinando múltiplas operações em menos chamadas ao banco de dados, melhorando significativamente o throughput em cenários de alto volume."
  />
  
  <Question
    question="Por que a manutenção automatizada é importante para sistemas de memória em produção?"
    options={[
      "Torna o sistema mais rápido",
      "Evita que o sistema se encha de memórias antigas e irrelevantes",
      "Melhora a segurança",
      "Reduz custos"
    ]}
    correct={1}
    explanation="A manutenção automatizada evita que o sistema acumule memórias antigas e irrelevantes que diminuiriam a velocidade de recuperação e desperdiçariam espaço de armazenamento."
  />
</Quiz>

## Exercício: Implante Seu Sistema de Memória

Configure um sistema de memória de produção:

1. **Configuração MongoDB**: Crie um cluster MongoDB Atlas
2. **API Básica**: Construa endpoints REST para operações de memória
3. **Monitoramento**: Adicione verificações de saúde e métricas
4. **Segurança**: Implemente limitação de taxa e validação de entrada

<CodeExample language="dockerfile" title="Dockerfile">
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .

EXPOSE 3000

CMD ["node", "app.js"]
</CodeExample>

<CodeExample language="yaml" title="docker-compose.yml">
version: '3.8'
services:
  memory-service:
    build: .
    ports:
      - "3000:3000"
    environment:
      - MONGODB_URI=${MONGODB_URI}
      - NODE_ENV=production
    restart: unless-stopped
</CodeExample>

## Resumo

Construímos um sistema completo de memória de produção com:

1. **Integração MongoDB**: Conexão de banco de dados pronta para produção e indexação
2. **Padrões de Escalonamento**: Processamento em lote e cache para alto throughput
3. **Segurança**: Limitação de taxa, validação de entrada e sanitização
4. **Monitoramento**: Verificações de saúde, métricas e rastreamento de erros
5. **Manutenção**: Limpeza e otimização automatizadas
6. **Implantação**: Docker e configuração de ambiente

<Callout type="success" title="Pronto para Produção">
Esses padrões fornecem uma base sólida para implantar sistemas de memória de agentes que podem lidar com escala e requisitos do mundo real.
</Callout>

## O Que Vem a Seguir?

Agora você tem todas as peças para construir sistemas de memória de agentes de produção:

1. **Comece Simples**: Comece com operações CRUD básicas
2. **Adicione Inteligência**: Implemente sinais de memória e estratégias de recuperação  
3. **Escale**: Adicione processamento em lote e cache conforme necessário
4. **Monitore**: Rastreie métricas e mantenha a saúde do sistema
5. **Evolua**: Implemente padrões avançados como esquecimento e consolidação

<Callout type="info" title="O Futuro da Memória de Agentes">
Como Richmond disse, "MongoDB é o provedor de memória para sistemas agênticos." Os padrões que você aprendeu ajudarão você a construir os agentes críveis, capazes e confiáveis que definem a próxima geração de aplicações de IA.
</Callout>

Parabéns! Você completou o caminho de aprendizado de Sistemas de Memória de Agentes. Agora está equipado para construir agentes inteligentes com capacidades sofisticadas de memória.