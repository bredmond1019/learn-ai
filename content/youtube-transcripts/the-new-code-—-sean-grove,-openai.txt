[00:00] [Music]

[00:15] [Music]

[00:24] Hello everyone. Thank you very much for [00:26] having me. Uh it's a very exciting uh [00:28] place to be, very exciting time to be. [00:31] Uh [00:33] second, uh I mean this has been like a [00:35] pretty intense couple of days. I don't [00:37] know if you feel the same way. Uh but [00:39] also very energizing. So I want to take [00:42] a little bit of your time today uh to [00:44] talk about what I see as the coming of [00:45] the new code. uh in particular [00:47] specifications which sort of hold this [00:49] promise uh that it has been the dream of [00:51] the industry where you can write your [00:53] your code your intentions once and run [00:56] them everywhere. [00:58] Uh quick intro uh my name is Sean I work [01:00] at uh OpenAI uh specifically in [01:03] alignment research and today I want to [01:05] talk about sort of the value of code [01:07] versus communication and why [01:08] specifications might be a little bit of [01:10] a better approach in general. [01:15] Uh I'm going to go over the anatomy of a [01:18] specification and we'll use the uh model [01:20] spec as the example. Uh and we'll talk [01:23] about communicating intent to other [01:26] humans and we'll go over the 40 syphency [01:28] issue uh as a case study. [01:31] Uh we'll talk about how to make the [01:33] specification executable, how to [01:36] communicate intent to the models, uh and [01:39] how to think about specifications as [01:42] code, even if they're a little bit [01:43] different. Um, and we'll end on a couple [01:45] of open questions. So, let's talk about [01:48] code versus communication. [01:51] Real quick, raise your hand if you write [01:54] code and vibe code counts. [01:57] Cool. Keep them up if your job is to [02:00] write code. [02:03] Okay. Now, for those people, keep their [02:05] head up if you feel that the most [02:07] valuable professional artifact that you [02:10] produce is code. [02:13] Okay, there's quite a few people and I [02:15] think this is quite natural. We all work [02:18] very very hard to solve problems. We [02:20] talk with people. We gather [02:22] requirements. We think through [02:24] implementation details. We integrate [02:25] with lots of different sources. And the [02:28] ultimate thing that we produce is code. [02:31] Code is the artifact that we can point [02:33] to, we can measure, we can debate, and [02:35] we can discuss. uh it feels tangible and [02:38] real but it's sort of underelling the [02:42] job that each of you does. Code is sort [02:45] of 10 to 20% of the value that you [02:47] bring. The other 80 to 90% is in [02:51] structured communication. [02:53] And this is going to be different for [02:54] everyone, but a process typically looks [02:56] something like you talk to users in [02:58] order to understand their challenges. [03:01] You distill these stories down and then [03:03] ideulate about how to solve these [03:06] problems. What what is the goal that you [03:08] want to achieve? You plan ways to [03:11] achieve those goals. You share those [03:13] plans with your colleagues. [03:16] Uh you translate those plans into code. [03:19] So this is a very important step [03:20] obviously. And then you test and verify [03:24] not the code itself, right? No one cares [03:27] actually about the code itself. What you [03:28] care is when the code ran, did it [03:32] achieve the goals, did it alleviate the [03:34] challenges of your user? You look at the [03:37] the effects that your code had on the [03:40] world. So talking, understanding, [03:44] distilling, ideulating, [03:48] planning, sharing, translating, testing, [03:51] verifying. These all sound like [03:53] structured communication to me. And [03:57] structured communication is the [03:59] bottleneck. [04:00] Knowing what to build, talking to people [04:03] and gathering requirements, knowing how [04:05] to build it, knowing why to build it, [04:08] and at the end of the day, knowing if it [04:10] has been built correctly and has [04:11] actually achieved the intentions that [04:13] you set out with. [04:15] And the more advanced AI models get, the [04:18] more we are all going to starkly feel [04:21] this bottleneck. [04:24] Because in the near future, the person [04:26] who communicates most effectively is the [04:29] most valuable programmer. And literally, [04:33] if you can communicate effectively, you [04:35] can program. [04:37] So, let's take uh vibe coding as an [04:39] illustrative example. Vibe coding tends [04:42] to feel quite good. And it's worth [04:44] asking why is that? Well, vibe coding is [04:47] fundamentally about communication first. [04:50] And the code is actually a secondary [04:52] downstream artifact of that [04:54] communication. [04:55] We get to describe our intentions and [04:57] our the outcomes that we want to see and [04:59] we let the model actually handle the [05:01] grunt work for us. And even so, there is [05:04] something strange about the way that we [05:06] do vibe coding. We communicate via [05:10] prompts to the model [05:12] and we tell them our intentions and our [05:14] values and we get a code artifact out at [05:17] the end and then we sort of throw our [05:20] prompts away they're ephemeral [05:24] and if you've written TypeScript or Rust [05:27] once you put your your code through a [05:29] compiler or it gets down into a binary [05:32] no one is happy with that binary. That [05:35] wasn't the purpose. It's useful. In [05:38] fact, we always regenerate the binaries [05:40] from scratch every time we compile or we [05:42] run our code through V8 or whatever it [05:44] might be from the source spec. It's the [05:47] source specification that's the valuable [05:50] artifact. [05:52] And yet when we prompt elements, we sort [05:53] of do the opposite. We keep the [05:55] generated code and we delete the prompt. [05:58] And this feels like a little bit like [05:59] you shred the source and then you very [06:01] carefully version control the binary. [06:05] And that's why it's so important to [06:07] actually capture the intent and the [06:09] values in a specification. [06:12] A written specification is what enables [06:14] you to align humans on the shared set of [06:17] goals and to know if you are aligned if [06:20] you actually synchronize on what needs [06:22] to be done. This is the artifact that [06:24] you discuss that you debate that you [06:26] refer to and that you synchronize on. [06:29] And this is really important. And so I [06:30] want to nail this this home that a [06:32] written specification effectively aligns [06:35] humans [06:37] and it is the artifact that you use to [06:40] communicate and to discuss and debate [06:42] and refer to and synchronize on. If you [06:45] don't have a specification, you just [06:47] have a vague idea. [06:50] Now let's talk about why specifications [06:52] are more powerful in general than code. [06:56] Because code itself is actually a lossy [06:58] projection from the specification. [07:01] In the same way that if you were to take [07:03] a compiled C binary and decompile it, [07:06] you wouldn't get nice comments and uh [07:09] well-n named variables. You would have [07:11] to work backwards. You'd have to infer [07:13] what was this person trying to do? Why [07:15] is this code written this way? It isn't [07:17] actually contained in there. It was a [07:18] lossy translation. And in the same way, [07:21] code itself, even nice code, typically [07:24] doesn't embody all of the intentions and [07:27] the values in itself. You have to infer [07:30] what is the ultimate goal that this team [07:32] is trying to achieve. Uh when you read [07:35] through code, [07:37] so communication, the work that we [07:39] establish, we already do when embodied [07:41] inside of a written specification is [07:43] better than code. It actually encodes [07:46] all of the the necessary requirements in [07:48] order to generate the code. And in the [07:51] same way that having a source code that [07:53] you pass to a compiler allows you to [07:56] target multiple different uh [07:58] architectures, you can compile for ARM [08:01] 64, x86 or web assembly. The source [08:04] document actually contains enough [08:06] information to describe how to translate [08:09] it to your target architecture. [08:11] In the same way, a a sufficiently robust [08:15] specification given to models will [08:18] produce good TypeScript, good Rust, [08:21] servers, clients, documentation, [08:24] tutorials, blog posts, and even [08:26] podcasts. [08:27] Uh, show of hands, who works at a [08:30] company that has developers as [08:32] customers? [08:34] Okay. So, a a quick like thought [08:36] exercise is if you were to take your [08:38] entire codebase, all of the the [08:40] documentation, oh, so all of the code [08:43] that runs your business, and you were to [08:45] put that into a podcast generator, could [08:47] you generate something that would be [08:49] sufficiently interesting and compelling [08:50] that would tell the users how to [08:53] succeed, how to achieve their goals, or [08:55] is all of that information somewhere [08:57] else? It's not actually in your code. [09:01] And so moving forward, the new scarce [09:03] skill is writing specifications that [09:06] fully capture the intent and values. And [09:10] whoever masters that again becomes the [09:12] most valuable programmer. [09:15] And there's a reasonable chance that [09:16] this is going to be the coders of today. [09:19] This is already very similar to what we [09:21] do. However, product managers also write [09:24] specifications. Lawmakers write legal [09:26] specifications. [09:28] This is actually a universal principle. [09:31] So with that in mind, let's look at what [09:32] a specification actually looks like. And [09:35] I'm going to use the OpenAI model spec [09:37] as an example here. So last year, OpenAI [09:40] released the model spec. And this is a [09:42] living document that tries to clearly [09:46] and unambiguously [09:47] express the intentions and values that [09:50] OpenAI hopes to imbue its models with [09:52] that it ships to the world. [09:57] and it was updated in in uh February and [10:00] open sourced. So you can actually go to [10:02] GitHub and you can see the [10:03] implementation of uh the model spec and [10:07] surprise surprise it's actually just a [10:08] collection of markdown files just looks [10:11] like this. Now markdown is remarkable. [10:15] It is human readable. It's versioned. [10:17] It's change logged and because it is [10:20] natural language everyone in not just [10:23] technical people can contribute [10:25] including product legal safety research [10:27] policy they can all read discuss debate [10:32] and contribute to the same source code. [10:35] This is the universal artifact that [10:37] aligns all of the humans as to our [10:40] intentions and values inside of the [10:42] company. [10:44] Now, as much as we might try to use [10:47] unambiguous language, there are times [10:49] where it's very difficult to express the [10:51] nuance. So, every clause in the model [10:55] spec has an ID here. So, you can see [10:57] sy73 here. And using that ID, you can [11:01] find another file in the repository [11:03] sy73.mmarkdown [11:05] or md uh that contains one or more [11:08] challenging prompts [11:10] for this exact clause. So the document [11:13] itself actually encodes success criteria [11:18] that the the model under test has to be [11:21] able to answer this in a way that [11:22] actually adheres to that clause. [11:27] So let's talk about uh syphy. Uh [11:31] recently there was a update to 40. I [11:34] don't know if you've heard of this. Uh [11:36] there uh caused extreme syphy. uh and we [11:41] can ask like what value is the model [11:44] spec in this scenario and the model spec [11:48] serves to align humans around a set of [11:50] values and intentions. [11:53] Here's an example of sycancy where the [11:55] user calls out the behavior of being uh [11:58] syphants uh or sophantic at the expense [12:01] of impartial truth and the model very [12:04] kindly uh praises the user for their [12:06] insight. [12:09] There have been other esteemed [12:10] researchers uh who have found similarly [12:13] uh [12:15] similarly uh concerning examples [12:19] and this hurts [12:23] uh shipping sycopency in this manner [12:26] erodess trust. [12:28] It hurts. [12:31] So and it also raises a lot of questions [12:33] like was this intentional? you could see [12:36] some way where you might interpret it [12:38] that way. Was it accidental and why [12:40] wasn't it caught? [12:42] Luckily, the model spec actually [12:44] includes a section dedicated to this [12:48] since its release that says don't be [12:50] sick of fantic and it explains that [12:53] while sophency might feel good in the [12:55] short term, it's bad for everyone in the [12:57] long term. So, we actually expressed our [13:00] intentions and our values and were able [13:01] to communicate it to others through this [13:07] So people could reference it and if we [13:11] have it in the model spec specification [13:13] if the model specification is our agreed [13:16] upon set of intentions and values and [13:18] the behavior doesn't align with that [13:20] then this must be a bug. [13:23] So we rolled back we published some [13:26] studies and some blog post and we fixed [13:28] it. [13:31] But in the interim, the specs served as [13:34] a trust anchor, a way to communicate to [13:36] people what is expected and what is not [13:38] expected. [13:43] So if just if the only thing the model [13:46] specification did was to align humans [13:49] along those shared sets of intentions [13:51] and values, it would already be [13:53] incredibly useful. [13:56] But ideally we can also align our models [13:59] and the artifacts that our models [14:01] produce against that same specification. [14:05] So there's a technique a paper that we [14:06] released uh called deliberative [14:08] alignment that sort of talks about this [14:09] how to automatically align a model and [14:12] the technique is uh such where you take [14:15] your specification and a set of very [14:17] challenging uh input prompts and you [14:19] sample from the model under test or [14:21] training. [14:23] You then uh take its response, the [14:25] original prompt and the policy and you [14:27] give that to a greater model and you ask [14:28] it to score the response according to [14:32] the specification. How aligned is it? So [14:34] the document actually becomes both [14:36] training material and eval material [14:40] and based off of this score we reinforce [14:42] those weights and it goes from you know [14:45] you could include your specification in [14:47] the context and then maybe a system [14:48] message or developer message in every [14:50] single time you sample and that is [14:52] actually quite useful. a prompted uh [14:54] model is going to be somewhat aligned, [14:56] but it does detract from the compute [14:57] available to solve the uh problem that [15:01] you're trying to solve with the model. [15:02] And keep in mind, these specifications [15:04] can be anything. They could be code [15:06] style or testing requirements or or [15:08] safety requirements. All of that can be [15:10] embedded into the model. So through this [15:13] technique you're actually moving it from [15:14] a inference time compute and actually [15:17] you're pushing down into the weights of [15:19] the model so that the model actually [15:21] feels your policy and is able to sort of [15:24] muscle memory uh style apply it to the [15:27] problem at hand. [15:29] And even though we saw that the model [15:31] spec is just markdown it's quite useful [15:34] to think of it as code. It's quite [15:36] analogous. [15:37] uh these specifications they compose [15:39] they're executable as we've seen uh they [15:42] are testable they have interfaces where [15:44] they they touch the real world uh they [15:46] can be shipped as modules [15:49] and whenever you're working on a model [15:52] spec there are a lot of similar sort of [15:54] uh problem domains so just like in [15:56] programming where you have a type [15:58] checker the type checker is meant to [15:59] ensure consistency where if interface A [16:02] has a dependent uh module B they have to [16:05] be consistent in their understanding of [16:07] one another. So if department A writes a [16:10] spec and department B writes a spec and [16:12] there is a conflict in there you want to [16:13] be able to pull that forward and maybe [16:15] block the publication of the the [16:18] specification as we saw the policy can [16:21] actually embody its own unit tests and [16:23] you can imagine sort of various llinters [16:25] where if you're using overly ambiguous [16:26] language you're going to confuse humans [16:28] and you're going to confuse the model [16:30] and the artifacts that you get from that [16:32] are going to be less satisfactory. [16:34] So specs actually give us a very similar [16:37] tool chain but it's targeted at [16:39] intentions rather than syntax. [16:42] So let's talk about lawmakers as [16:45] programmers. Uh [16:48] the US constitution is literally a [16:51] national model specification. It has [16:53] written text which is aspirationally at [16:56] least clear and unambiguous policy that [16:58] we can all refer to. And it doesn't mean [17:01] that we agree with it but we can refer [17:03] to it as the current status quo as the [17:05] reality. Uh there is a versioned way to [17:09] make amendments to bump and to uh [17:12] publish updates to it. There is judicial [17:14] review where a a grader is effectively [17:19] uh grading a situation and seeing how [17:20] well it aligns with the policy. And even [17:23] though the again because or even though [17:25] the source policy is meant to be [17:27] unambiguous sometimes you don't the [17:30] world is messy and maybe you miss part [17:32] of the distribution and a case falls [17:34] through and in that case the there is a [17:37] lot of compute spent in judicial review [17:40] where you're trying to understand how [17:41] the law actually applies here and once [17:43] that's decided it sets a precedent and [17:46] that precedent is effectively an input [17:48] output pair that serves as a unit test [17:50] that disambiguates and rein reinforces [17:52] the original policy spec. Uh it has [17:55] things like a chain of command embedded [17:58] in it and the enforcement of this over [18:01] time is a training loop that helps align [18:03] all of us towards a shared set of [18:05] intentions and values. So this is one [18:08] artifact that communicates intent. It [18:11] adjudicates compliance and it has a way [18:13] of uh evolving safely. [18:17] So it's quite possible that lawmakers [18:19] will be programmers or inversely that [18:21] programmers will be lawmakers in the [18:24] future. [18:26] And actually this apply this is a very [18:28] universal concept. Programmers are in [18:30] the business of aligning silicon via [18:33] code specifications. Product managers [18:36] align teams via product specifications. [18:38] Lawmakers literally align humans via [18:41] legal specifications. And everyone in [18:43] this room whenever you are doing a [18:45] prompt it's a sort of proto [18:46] specification. You are in the business [18:49] of aligning AI models towards a common [18:52] set set of intentions and values. And [18:55] whether you realize it or not you are [18:56] spec authors in this world and specs let [19:01] you ship faster and safer. Everyone can [19:04] contribute and whoever writes the spec [19:07] be it a [19:09] uh a PM uh a lawmaker an engineer a [19:13] marketer is now the programmer [19:17] and software engineering has never been [19:19] about code. Going back to our original [19:22] question a lot of you put your hands [19:24] down when you thought well actually the [19:25] thing I produced is not code. [19:28] Engineering has never been about this. [19:29] Coding is an incredible skill and a [19:31] wonderful asset, but it is not the end [19:33] goal. Engineering is the precise [19:35] exploration by humans of software [19:37] solutions to human problems. It's always [19:40] been this way. We're just moving away [19:42] from sort of the disperate machine [19:43] encodings to a unified human encoding uh [19:47] of how we actually uh solve these these [19:49] problems. Uh I want to thank Josh for [19:51] this uh credit. So I want to ask you, [19:54] put this in action. Whenever you're [19:57] working on your next AI feature, start [19:59] with a specification. [20:01] What do you actually expect to happen? [20:03] What's success criteria look like? [20:05] Debate whether or not it's actually [20:07] clearly written down and communicated. [20:09] Make the spec executable. Feed the spec [20:11] to the model [20:14] and test against the model or test [20:17] against the spec. And there's an [20:19] interesting question sort of in this [20:20] world given that there's so many uh [20:22] parallels between programming and spec [20:25] authorship. [20:27] I wonder what is the what does the IDE [20:30] look like in the future. you know, an [20:31] integrated development environment. And [20:33] I'd like to think it's something like an [20:34] inte like integrated thought clarifier [20:37] where whenever you're writing your [20:38] specification, it sort of ex pulls out [20:42] the ambiguity and asks you to clarify it [20:45] and it really clarifies your thought so [20:47] that you and all human beings can [20:49] communicate your intent to each other [20:51] much more effectively and to the models. [20:55] And I have a a closing request for help [20:58] which is uh what is both amenable and in [21:01] desperate need of specification. This is [21:04] aligning agent at scale. Uh I love this [21:07] line of like you then you realize that [21:09] you never told it what you wanted and [21:11] maybe you never fully understood it [21:12] anyway. This is a cry for specification. [21:15] Uh we have a new agent robustness team [21:17] that we've started up. So please join us [21:19] and help us deliver safe AGI for the [21:22] benefit of all humanity. [21:25] And thank you. I'm happy to chat. [21:29] [Music]