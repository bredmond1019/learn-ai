[00:00]  [00:00] weak, base, strong. Three levels of [00:04] model control, simple, and beautiful. We [00:08] now have access to the haik coup, [00:10] sonnet, and opus models in our sub [00:13] aents. In the background here, I have 12 [00:16] sub aents operating across these three [00:19] levels of intelligence, speed, and cost [00:21] conducting crypto research for me. [00:24] They're setting up my next big trade. [00:27] Now, obviously not financial advice, but [00:29] you can see here running 12 agents in [00:31] parallel with different levels of [00:33] compute, Haiku, Sonnet, and Opus, you [00:36] and I are able to do more deep research [00:39] and more wide research than we ever [00:41] could before. The Claudeco team [00:43] continues their blazing red hot streak [00:46] as they ship another set of surgical [00:49] minimal useful features. We have sub [00:51] agent model selection, agent mentions, [00:53] and hidden file mentions. We do have bad [00:56] news though. We have new rate limits. [01:00] Someone watching the Andy Dev Dan [01:02] channel took the infinite agentic loop, [01:04] parallelized it, and ran it 24/7 and [01:07] ruined it for the rest of us. In this [01:08] post, Anthropic mentioned something [01:10] really, really interesting that caught [01:12] my attention. We're committed to [01:13] supporting longunning use cases through [01:16] other options in the future. With the [01:18] success of Claude Code and the Claude 4 [01:20] series, you and I can bet that Enthropic [01:23] is betting on highly agentic longrunning [01:26] systems and models. So, I'm thinking [01:28] ahead toward what Enthropic could be [01:30] releasing next. But I have to say with [01:32] all the excitement around cloud code, [01:34] it's pretty clear engineers like you and [01:37] I and now a decent portion of the Genai [01:40] tech industry, we're all overexposed to [01:43] claw code. We have too many eggs in one [01:46] basket. This is bad investing. I don't [01:48] think these rate limits are unfair at [01:50] all, but it's woken me up. And maybe [01:51] it's woken you up, too. We need cloud [01:54] code alternatives. We have too many eggs [01:55] in one basket, right? We're addicted. We [01:58] need help. We're clawholics now. We need [02:01] alternatives. Not because cloud code [02:03] isn't great. It's because it's too [02:05] great. With these new rate limits coming [02:07] in, as they mentioned, it'll affect less [02:09] than 5% of users, but you and I, we're [02:12] probably in the 10 or 5%. And these rate [02:14] limits are coming. All right. August [02:16] 28th. It's kind of perfect timing that [02:18] this came out with their brand new model [02:20] selection feature. In this video, we're [02:21] going to take a look at that because you [02:23] can see across three versions. And you [02:25] know, speaking of limits, right, there's [02:26] my Opus limit coming up right here. But [02:28] you can see across three versions, you [02:30] know, I have Haiku, Sonnet, and Opus [02:31] running the exact same prompt. We're [02:33] going to dig into this so that we can [02:34] understand that we don't always need the [02:37] highest levels of compute to solve [02:39] problems. The ability to select the [02:41] right model for the job is ultra [02:43] important. And I think this powerful [02:45] weak base, strong model stack for agents [02:48] is going to be a great way to navigate [02:50] not just rate limits, but it's going to [02:52] help us navigate costs, speed, and [02:54] intelligence trade-offs. I've been [02:55] thinking about this for a while as I [02:57] continue to, you know, discuss, use, and [02:59] really lean on cloud code, we're [03:01] overlevered, right? Just like an [03:03] investor has too much stock, too much of [03:05] their portfolio in one tool. We have a [03:07] lot of engineering resources, time, [03:09] dependency on cloud code at this point. [03:11] So with the release of Quinn3 coder 480 [03:15] billion parameters everything that keeps [03:17] shipping inside of the Gemini CLI right [03:20] I'm keeping my eyes on all of these [03:21] agentic coding tools all these agentic [03:23] model developments and with uh the [03:26] recent news that anthropic had to [03:28] provoke open AAI's access to claude two [03:31] things are very very clear to me now [03:34] claw code has completely changed [03:36] engineering and alternatives are on the [03:40] way if you're an IND industry leader, [03:42] you will always be copied and cloned. [03:44] Cloud code is the industry leader for [03:46] agentic coding. It is being copied and [03:48] cloned all over the place. In upcoming [03:50] videos, we're going to be looking and [03:52] investigating, you know, some of these [03:54] open source alternatives, some other [03:55] closed source alternatives. It is time [03:57] to diversify. All right, but you know, [03:59] let's be super real. Uh, no one is close [04:02] to cloud code. Let's keep cooking with [04:04] the best agent coding tool in the game. [04:06] Let's break down a few powerful agent [04:08] orchestration patterns with sub aent [04:10] model selection so we can use the right [04:12] agent coding model for the job at hand [04:15] while avoiding these new rate limits. [04:17]  [04:23] My crypto research can run with this [04:25] single slash command and it kicked off [04:28] 12 agents. Right away we have to point [04:30] out something really really important. [04:32] Look at the time differences. Look at [04:33] the token differences. These small, [04:35] fast, cheap models are going to do less [04:38] work for you, but they're going to do it [04:39] in a short amount of time, while Sonnet [04:42] and Opus are going to scale up the [04:44] amount of tokens, the cost, and the time [04:46] consumed. You can see it's writing this [04:48] comprehensive summary for us with 12 [04:50] output tool calls in parallel. Let's let [04:52] our primary agent cook some more, and [04:54] let's answer the question, what does [04:56] model selection really offer you? [04:58] Ultimately, it lets you solve two [05:00] problems. model overkill, where you're [05:02] wasting tokens and money, and model [05:05] underperformance, where you waste time [05:07] having to improve your prompt or fire [05:09] off the larger, more powerful model [05:11] after wasting time on the cheaper model. [05:13] Okay, it's all about the tradeoff, [05:16] right? We're always trading off three [05:18] things when we're selecting our models: [05:20] performance, speed, and cost. You can [05:23] optimize for performance, you can [05:25] optimize for speed, and you can optimize [05:27] for cost. I always advocate that you [05:30] want performance over everything else, [05:33] right? This is why we spend to win. This [05:35] is why we have that big claw code max [05:37] $200 subscription, right? However much [05:39] you can push it, you want to be pushing [05:41] it for the compute. The compute is [05:43] absolutely worth it. There's nothing [05:44] more important in the generative AI age [05:47] as an engineer than your ability to [05:49] scale up compute and use it to solve [05:52] real engineering problems. This is the [05:54] name of the game. This is what every [05:56] winning engineer is doing right now. I [05:58] guarantee you that bar none. You know, [06:00] when we double click into this, it's [06:02] quite a simple equation, right? We have [06:03] Hiku 3.5, our weak model. We have Sonnet [06:06] 4, our balanced workhorse model. And [06:09] then, of course, Opus 4. When you're [06:11] solving real problems, when you're [06:13] building out things and you want [06:14] performance over everything, you choose [06:16] the best model. And you can even push [06:18] this further, right? Model selection is [06:19] just layer one. The next layer is of [06:21] course thinking, right? You can specify [06:24] the information dense keyword the IDK [06:26] think hard ultra think right anthropic [06:29] has encoded this keyword for us so that [06:32] in our prompts we can activate this [06:33] feature whenever we need to right and I [06:36] highly highly recommend if you're not [06:37] doing this you need to be using this if [06:39] you look at the charts if you go on [06:40] artificial analysis if you run you know [06:42] examples yourself 4 thinking beats opus [06:45] 4 bass also of course opus 4 thinking [06:48] beats sonet 4 thinking so that's a [06:50] really important call out there are [06:51] other dimensions of your model that you [06:53] can push. This is the trade-off we're [06:55] making when we're selecting models, when [06:56] we're using models. And you know, [06:58] there's a fourth kind of hidden [06:59] dimension here. We also have to work [07:01] against um APIs and rate limits here. [07:03] This is kind of the hidden dimension. [07:05] This is probably something we're going [07:06] to want to add in the future as we scale [07:08] up our compute and start running those [07:10] big big long running, we're talking [07:12] hours and hours and hours long [07:14] engineering workflow. All right. Why are [07:15] we hitting these rate limits more? [07:17] What's going on, right? How are we able [07:18] to scale up further? It's of course [07:20] because of sub agents, right? We can now [07:22] spin up multiple agents from our primary [07:24] agent. We covered this in our last [07:26] video. And now we have more compute than [07:28] ever. And we can specify what our sub [07:31] aents do. We can now write system [07:33] prompts for our sub aents. Okay. So, we [07:35] just had this crypto analysis run. I [07:37] have a couple interesting ideas here [07:38] that I want to share with you. All [07:39] stemming from this crypto research [07:41] custom/comand. All right. And so, you [07:43] know, funnily enough, um I am at my rate [07:45] limits for the day. This is kind of [07:46] perfect timing. I'm glad I'm filming it [07:48] right here. Uh rate limits are [07:50] obnoxious. you know, I'm on that $200 [07:52] plan, but you can still see here I am [07:54] hitting rate limit. There is absolutely [07:56] an argument for selecting the right [07:59] model for the job, right? You don't [08:00] always need top-end compute. And [08:02] especially when we're deploying our [08:03] agents into production environments, you [08:05] want to use the right model for the job. [08:07] You don't want to go overkill, right? [08:08] Remember, model selection solves two [08:10] problems. Model overkill and model [08:12] underperformance. You want to hit that [08:13] sweet spot if and when it matters. A lot [08:16] of the time, you probably do this too, [08:17] right? A lot of the times we just go [08:19] model and we just go right to opus, [08:20] right? I just want the best model and [08:22] then you always throw on thinking mode [08:24] and you let it operate at the highest [08:26] possible intelligence level just to get [08:28] the job done, right? Uh this is great. I [08:30] do this all the time too. But as you're [08:32] scaling up parallel sub agents, parallel [08:34] agents, running multi- aent workflows, [08:36] right? Ondevice and offdevice, um these [08:39] rate limits, I think, are going to come [08:40] into play more and more. Feel like rate [08:42] limits have never truly been more [08:44] important than with compute, right? [08:46] because let's say you hit the daily or [08:48] the weekly limit. Uh that's it, right? [08:50] And this is also why it's so important [08:52] for us to find alternatives. Anyway, [08:53] more on that in the future. Make sure [08:54] you're subscribed and like we're going [08:56] to be investigating and benchmarking [08:57] agentic coding tool alternatives. Um [09:00] back to this prompt, right? Let's talk [09:01] about model selection. So, let's go [09:03] ahead and open up cursor. Let's [09:05]  [09:05] understand this crypto research prompt. [09:06] Couple new features coming out of the [09:08] cloud code team. Let's just go ahead and [09:10] pull up the official docs/re. And we [09:12] have three important features to cover [09:14] here. So we have agents with custom [09:16] model support, appmentions for custom [09:18] agents, and we have app meions for [09:20] hidden files. This is super important. [09:22] Now we can do something like this. And [09:24] now we can see all of our cloud files. [09:26] And do we have anything else here? Let's [09:27] see. MCP, right? So now we can see our [09:29] MCP file here. What's going on here? So [09:32] I have a custom slash command that is [09:34] kicking off 12 agents. And really it's [09:35] kicking off four distinct solutions with [09:39] three levels of agent each, right? [09:42] Haiku, sonnet, opus. This is a great way [09:44] to understand what model do I really [09:46] need to solve this problem. Okay, so you [09:48] can see they're working off a bunch of [09:50] crypto agents doing crypto research, [09:52] macro analysis, investment play ideas, [09:54] so on and so forth, right? So we can go [09:56] ahead and just collapse. Here's the [09:57] prompt format we have here. Top level [09:58] kind of purpose variables. We're just [10:00] passing in a ticker. We have our agent [10:02] groups. So we're defining, you know, [10:04] what teams of agents are going to run. [10:06] And then we have execution instructions. [10:07] So this is, you know, I also like to [10:09] call this workflow. And then we have our [10:12] output format. So output format super [10:14] important when you're writing these [10:15] prompts. This forces your primary agent [10:17] to communicate to you what you want your [10:18] output format to be. And for your [10:20] agents, it forces your agents to report [10:23] their output. So right away you can see [10:25] something interesting here in this [10:27] system prompt for my crypto market [10:29] agent. There's not much here. In fact, [10:31] all I'm doing here is referencing [10:33] another prompt. And so this is a pattern [10:35] that I want to share with you here. You [10:36] can have sets of agents at different [10:38] levels, right? Different model levels, [10:40] different descriptions, right? so that [10:42] you can ABC test against one prompt, [10:45] right? So, I think this is a really [10:46] powerful pattern. It's also useful so [10:48] that you can test this on your primary [10:50] agent, right? Instead of it just being [10:52] one system prompt inside a specific [10:55] agent, you can test multiple prompts [10:57] against multiple agents. Now, you do [10:59] have to keep in mind this is still the [11:00] system prompt, right? So, what we have [11:02] here is a system prompt, right? And you [11:05] can see here we have that output format [11:06] from our agent system prompt. The key [11:09] thing here is that you know, let me copy [11:10] this uh reference here. You can see for [11:13] our three agents, Hiku, Opus, Sonnet, [11:15] we're using this exact same prompt. So [11:18] here's Hiku, here's Opus. You can see [11:20] all that change there. Let's go back and [11:22] forth. All that's changing there is our [11:24] model color and agent name, right? So [11:27] this lets us again ABC test our model [11:30] and our description. Okay, this is cool. [11:33] Inside of each one of these prompts, we [11:34] are of course doing specific crypto [11:36] analysis, crypto research. So let's go [11:38] ahead and open up macro [11:39] cryptocorrelation. You know, inside of [11:41] this prompt, let's go ahead and just [11:42] open this up. We have, you know, classic [11:44] prompt format, purpose, instructions, [11:45] workflow, output. You are a macro crypto [11:48] correlation analysis expert. Here we [11:50] want to understand how global macro [11:53] plays into the traditional market. Of [11:54] course, we have instructions and then we [11:56] have our workflow. We're at our [11:57] step-by-step play for the sub aent. [12:00] Always remember this is the system [12:01] prompt we're operating in here when [12:03] we're calling sub aents. And you know, [12:06] just to make this super clear, we [12:07] covered this in our previous sub aent [12:08] video from last week. You are prompting [12:10] your primary agent. Your primary agent [12:13] is prompting your sub agents. Your sub [12:14] agents are responding to your primary [12:17] agent, not to you. The flow of [12:19] information matters here, especially [12:21] when you start scaling up to, and we've [12:22] covered this, multi- aent workflow [12:24] orchestration where you have multiple [12:26] prompts firing off back to back to back. [12:27] It all feeds into your primary agents [12:29] context window. Okay? It doesn't return [12:31] to you. So when you read these agent [12:33] prompts, right, we have a bunch of [12:34] underscore agent_prompt. [12:36] MD, these are all returning to your [12:39] primary agent. And so that's why we have [12:42] this and we if we go up to the top level [12:43] crypto research, we have this output [12:45] format call on the top level crypto [12:48] research. Right? This is that top level [12:50] prompt that we executed to kick off our [12:52] 12 agents across three different models. [12:54] Their output format here is really [12:56] important. So, we're taking each [12:57] response directly with no modifications, [13:00] no summarizations, and no changes. Okay, [13:03] super important. Again, we're [13:05] referencing anthropics encoded keyword [13:07] important. We're prefixing this with [13:09] important so our agent pays more [13:10] attention to it. And then we have our [13:12] output format. All right, so now we [13:13] should be able to just find these, [13:14] right? So, if we open this up, collapse [13:16] everything. And we go into outputs, you [13:18] can see we have two files here, 10 5614. [13:21]  [13:22] Here we go. There are all of our [13:23] prompts. You can see it's in that exact [13:24] same format as specified. And then we [13:26] can take a look at each level. Okay. And [13:29] so this is the really important part, [13:30] right? Every level matters, right? You [13:32] don't always need opus for certain [13:34] things. You don't always need sonnet, [13:36] but you can see in some cases you can [13:38] drop all the way down to a cheap fast [13:40] haiku model. Let's see if for something [13:42] like a cryptocoin analyzer. Do a [13:45] sidebyside here. So that's haiku. Here's [13:47] opus. Here's sonnet. You know, very [13:49] clearly the haiku model is having a [13:51] problem. It's having a challenge with [13:52] the format. And if we open up our [13:54] cryptocoin prompt and go down to our [13:57] output format, you can always check for [13:59] model strength by looking to see if it [14:01] can obey your output formats. So we're [14:03] looking for output in this structure, [14:05] cryptocurrency analysis. And you can see [14:07] here right away IU goes off the rails, [14:10] right? If we move over to sonnet, we can [14:12] see that it's not exact, but it gets a [14:14] lot closer. We have, you know, market [14:16] data, recent news and developments. [14:18] There's the market data and if we search [14:20] for news, you can see we have a news [14:22] section here on sonnet, right? So, this [14:24] looks better, right? We can work with [14:25] this. Um, if we go to Opus, however, and [14:29] search for that exact header, we can see [14:31] we're getting that exact header. And [14:33] this is a really important call out, [14:34] right? If you want maximum performance, [14:37] you always scale it up to that top [14:39] model, right? You pay to play. And this [14:42] is something I see some engineers are so [14:44] scared to spend. they're so scared to, [14:47] you know, use that maximum compute and [14:48] really pay to play. This is a massive [14:50] advantage. Understanding what the [14:52] maximum capabilities are and getting the [14:54] advantage of using them will set you [14:57] ahead. It'll break you away from the [14:59] pack. When I want to use the best, I [15:00] don't hesitate. Okay? You can even push [15:02] that further. Of course, as you know, [15:04] you can add thinking to these models. [15:06] You can force them to think more. Use [15:08] their reasoning effort. Increase [15:09] intelligence even further. Of course, [15:11] you're going to spend more to do this, [15:12] right? they're still generating those [15:14] tokens even if you can't see them. And [15:16] you want to be especially careful with [15:17] this with sub agents, right? Because [15:19] this stuff is still happening. You want [15:21] to be making sure that you're using the [15:23] value of your top level agents, [15:25] specifically your opus agents or [15:26] whatever your strong model is. Make sure [15:29] you're getting value out of this. Don't [15:30] be wasteful with this stuff. Unless [15:32] you're learning something or [15:33] experimenting, you really want to, you [15:35] know, use these models with a clear [15:37] purpose. All right, keep that in mind, [15:39] too. And always remember, you can push [15:40] the model further with thinking mode. [15:41] Just to mention it, uh, Sonic 4th [15:43] thinking is very, very powerful, right? [15:45] More broadly, this pattern of having a [15:47] weak base and strong model for your [15:50] agent model stack is super powerful, [15:52] right? It's super important because you [15:53] don't always need Opus, right? Sometimes [15:54] you're just summarizing some work, so [15:56] you can drop down to a simple model. And [15:58] this applies across model providers, [15:59] right? Gemini Flash Light, 2.5 Flash, [16:02] 2.5 Pro, and then, you know, there are [16:04] bigger levels above and below. Gemini [16:06] just put out their deep think model, [16:08] while OpenAI has 03 Pro. They have their [16:11] new agent model and they have apparently [16:14] GPT5. We'll see about that. I think this [16:16] is a great pattern for you to kind of [16:17] select models and use the right model, [16:19] right? It's all about that PF speed cost [16:21] trade-off and you know the kind of [16:23] hidden layer rate limits. We're scaling [16:25] up our compute across multiple [16:26] dimensions. Now, if you want to scale, [16:29] it's pretty clear that reusable prompts [16:31] aka custom/comands and sub agents is the [16:34] way to scale up your compute and get [16:35] more work done than ever. So, this is a [16:37] powerful agent pattern you can use. You [16:39] have your top level agent calling a [16:41] custom SL command. Here we're doing [16:42] crypto research. This fires off many sub [16:45] aents, right, across different model [16:47] levels and then it takes the results and [16:50] refuses them, right, in a big way. We're [16:52] just doing what we've done for years on [16:54] the channel, prompt chaining and fusion [16:56] chaining. Okay, we've covered this stuff [16:58] a long time ago before reusing models [17:00] even existed. Inside of your agents, you [17:03] can do something really powerful. You [17:04] can create dedicated agent prompts to [17:07] reuse across different agents to [17:09] understand what model performance you [17:11] really need. That looks like this. If we [17:13] go into agents, we go into crypto, you [17:14] can see we have cryptocoin analyzer [17:17] haiku. We have the exact same version [17:18] for sonnet. Right? There's that sonnet. [17:21] And we have the exact same version for [17:23] opus as well. So it's all just a small [17:25] tweak to understand what model you [17:28] really need for the job you're doing. [17:29] And this is why it's so important to [17:31] isolate your prompt for your sub agents. [17:33] This is just a pattern. It's an idea [17:35] that you can use. And another advantage [17:37] here is of course we can just hop into a [17:39] new agent and we can just fire this [17:41] prompt off oursel right on the top [17:43] level. Okay? You know whenever you want [17:45] to you can understand what your prompt [17:47] is doing and how it performs by just [17:49] running it on the top level. Right? So [17:50] here we can just run our cryptocoin [17:52] analyzer agent and actually we need to [17:53] pass in a uh let's do B&B. This is a [17:56] great way to understand what your prompt [17:58] does end to end and to make tweaks to it [18:00] by running it on the top level right in [18:02] your primary agent. A lot of things get [18:04] lost when you're running sub aents. So [18:06] you can use this dedicated agent prompt [18:08] pattern to understand, you know, what [18:11] model you really need for the job. The [18:12] way I look at it is a lot of my simpler [18:14] tasks where we're just generating unique [18:15]  [18:16] names for files where we're doing some [18:19] small file moving, some file migration, [18:21] some quick summarizations. Haiku 3.5 can [18:24] do a lot of that stuff, right? In fact, [18:26] you probably have seen, you know, this [18:27] little popup here from cloud code. Guess [18:30] who's running that? This is a ha coup [18:31] model making up, you know, a relevant [18:33] one-word description, right? The perfect [18:35] example for that, right? You don't need [18:36] a big model to do that. You need [18:37] something fast and cheap and simple. So, [18:39] that's a small example of how you can [18:40] use a small fast model and avoid using a [18:43] bigger, stronger model, right? Even like [18:44] Sonnet 4. Then there's of course the [18:46] Sonet 4. This is a workhorse model, [18:48] right? This is our base level model. [18:50] This is going to be a great balance. I [18:51] think a lot of work happening right now [18:53] is coming out of Sonet 4. It's funny to [18:55] think about, you know, what model is [18:56] responsible for the most code in the [18:58] world. And I think right now it's very [19:00] clearly sonnet 4. And then of course we [19:02] have opus, right? When you're doing [19:04] serious work, when you're putting the [19:05] pellet to the metal, you use opus 4 and [19:07] you scale it with thinking mode, right? [19:08] I do this all the time. Any complex [19:10] work, any, you know, serious engineering [19:12] work, production work, opus for think, [19:14] burn up the tokens, hit the right [19:16] limits, it doesn't matter. The compute [19:17] is there for you to use, right? And so [19:20] we can take all these models, we can [19:21] take them in thinking mode, we can embed [19:23] them in sub aents and scale them up, [19:25] right? And so in the end we get [19:26] something like this, right? A powerful [19:28] multi- aent orchestration workflow. This [19:30] is just one simple example of work [19:31] happening. All feeds back into the [19:33] primary agent. Primary agent can then [19:35] execute on all that work, right? This is [19:36] just one workflow. Again, we covered [19:38] this in our previous week's video. I'll [19:39] make sure to link that. You want to [19:40] understand the model controls. You want [19:42] to understand your tool and you want to [19:43] understand what you can do with them. [19:45] Right? every week here. That's what [19:46] we're pushing toward. Understanding the [19:48] best agent coding tools so that we can [19:51] build systems that work for us while we [19:54] sleep. That's always been the focus. [19:56] It's always been the mission of this [19:58] channel. We're going to build living [20:00] software that works for us while we [20:01] sleep. We're getting closer than ever [20:03] with cloud code, with these incredible [20:06] longrunning jobs and sub agents. But we [20:08] also need to make sure that you know [20:10]  [20:10] when rate limits pop up when the next [20:13] set of restrictions or you know whatever [20:16] comes next we need to make sure we can [20:17] diversify. So you know again as you know [20:20] this is like my 15th cloud code video in [20:22] a row unprecedented for this channel but [20:24] um I follow and focus on the signal of [20:26] the best tool for the job right now for [20:28] engineering. There's no better tool than [20:29] cloud code but we need to make sure we [20:32] diversify. We can't be so reliant on a [20:34] single tool on a single set of models, [20:38] right? We have to make sure that we can [20:40] do more. We have to make sure that, you [20:43] know, we have other agent coding tools. [20:45] So, I'm keeping an eye out for that, [20:46] right? We just had that Quinn 3 drop. We [20:49] have Gemini CLI improving all the time. [20:51] And then we have a bunch of open source [20:52] alternatives that I'm going to give a [20:53] serious sit down to really soon here. If [20:56] you've reached out or emailed, I'm going [20:58] to be covering a lot of the open source [20:59] agent coding tools coming up here and [21:02] comparing them, doing really concrete [21:04] comparisons to the industry leader, [21:06] Cloud Code. Don't underestimate the [21:08] power of model selection, right? Our [21:10] crypto research agents did a ton of [21:12] research for us. We can look at Opus big [21:14] plays, right? Let's go into markdown [21:16] format. Crypto play report, strong [21:18] bullish momentum, XRP, interesting, [21:21] right? SEC settlement rally. Thesis, [21:23] there's an execution, right? Right. So [21:24] we have this interesting bullc case. All [21:26] this interesting research, right? Salana [21:28] DeFi ecosystem. Okay. Huge huge return [21:30] on investment. Again, not investment [21:32] advice. Uh we're just looking at some of [21:34] the results that our agents created for [21:35] us. Okay. Crypto investment agent [21:38] prompt. If we look at the uh response [21:40] format once again, we can see that Opus [21:44] is obeying the prompt output format very [21:46] well. We can open up the equivalent [21:48] sonnet version. And you can see sonnet [21:50] is getting close here as well. Um, it [21:53] also has this, you know, little header [21:54] here which we didn't ask for. But [21:56] overall, you know, looks like Sonnet is [21:58] doing the job for the crypto investment [22:00] plays idea, right? You know, it has a [22:01] play here, crypto accumulation at key [22:03] supports. You know, it's identified some [22:05] dip spots for us to come into, right? We [22:07] have our kill criteria, right? This is a [22:10] concrete section we ask for from this [22:12] template. This looks great. We have [22:13] Ethereum liquid staking opportunity, [22:16] six-month time frame, so on and so [22:18] forth, right? And then we can drop all [22:19] the way down to Haiku. You can see here [22:21] haiku way off. This problem is too [22:24] complicated for haiku. Right? And this [22:26] pattern repeats across the rest of our [22:29] analysis. Right? So this is one more [22:31] idea that you can add to your toolbox [22:33] when you're agent coding. Use the right [22:35] model for the job. Isolate your system [22:37] prompts so that you can run them against [22:39] any model that you want. And make sure [22:42] you are diversifying. I love cloud code [22:44] just as much as the next engineer. We [22:46] were one of the first channels to cover [22:47] it. But um drop a like and a comment if [22:50] you were here before and during the [22:52] early days of covering Claude Code. It's [22:54] not over. It's definitely not over. [22:56] Claude Code is an incredible tool. The [22:57] team is shipping back to back to back. [22:59] But we have to think as independent [23:01] actors. We can't overinvest into one [23:04] tool. Okay, this is a really balanced [23:06] take out of Enthropic. these weekly [23:08] limits had to get set into place because [23:10] yes, people are abusing this incredible [23:12] tool with 24/7 hour in the background [23:15] agents and agent workflows. But um you [23:18] know it's important that we diversify, [23:19] right? Every single day we have more and [23:21] more options emerging. Quinn 3 coder [23:23] Gemini CLI with the new Gemini models [23:25] pretty crazy you know anthropic getting [23:27] kind of defensive here around the API [23:29] we'll see how that progresses a hend [23:31] coding tools will continue to evolve as [23:33] well as the models but what remains the [23:35] same is of course the principles of AI [23:37] coding keep your eyes on the big three [23:39] context model and prompt understand how [23:41] to use these three elements to solve [23:43] problems that you face because if you [23:45] master these you will master Genai no [23:48] matter the current drama no matter the [23:50] current rate limits no matter the models [23:52] All right, stick to the principles of AI [23:54] coding. I'll be starting the countdown [23:56] for the phase 2 aentic coding course [23:59] very very soon. I'll be locking in a [24:01] release date for that. So stay tuned for [24:03] that. If you made it to the end, drop a [24:04] comment and let me know what you think [24:06] about the current agentic coding [24:08] ecosystem and these brand new rate [24:10] limits around cloud code. If you're [24:11] experimenting with alternatives, let me [24:13] know what you're working with and I'll [24:15] use that as a great starting place. No [24:17] matter what, stay focused and keep [24:20] building.