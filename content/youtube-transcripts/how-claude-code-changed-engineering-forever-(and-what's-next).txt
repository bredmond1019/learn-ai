[00:00]  [00:01] It started quietly. No grand [00:04] announcements, no hype marketing, just a [00:06] simple command line interface that would [00:09] change engineering forever. Cloud Code [00:12] emerged not as a tool, but as a partner [00:16] in a gentic system that understood [00:19] context, state, and most importantly, [00:22] engineering. It consistently reasons [00:25] about code at a level previously thought [00:29] impossible. And the crazy part is there [00:31] was no rag. There was no UI. Only the [00:35] context, the model, and the prompt. The [00:37] engineering community watched with a [00:40] mixture of skepticism and awe. As early [00:42] adopters like you and I started [00:45] reporting productivity gains that defied [00:48] belief, tasks that once took days were [00:51] completed in hours, then minutes as we [00:55] improved our agentic coding. It's clear [00:59] looking back this time period marks the [01:02] beginning of a new phase of engineering. [01:05]  [01:05] Welcome back to the channel. In this [01:07] video, I want to answer the question and [01:09] I want to talk about how cloud code [01:12] changed engineering. We spend so much [01:15] time planning, building, and learning. [01:17] We don't take enough time to stop, [01:19] reflect, digest, and think hard about [01:23] the incredible things we can do with our [01:25] agentic coding tools. By breaking down [01:27] how clog code changed engineering, we [01:31] can understand the stateofthe-art, which [01:33] sets us up for making bets on the future [01:35] and prepares us for what's coming next, [01:38] so we can make the highest return on [01:40] investment bets on our precious [01:43] engineering time. How has cloud code [01:45] changed engineering? Just like deep [01:48] learning worked, the agent architecture [01:50]  [01:50] worked. Sam Alman called this out in the [01:53] intelligence age post. And just like [01:55] deep learning worked, the agent [01:57] architecture worked. We're not just [01:59] chatting with language models in chat [02:01] interfaces. We're commanding compute. [02:04] We're prompting agents. We're composing [02:07] the language model to the next level of [02:09] abstraction, the agent. It's clear that [02:12] this transition marks phase 2 of the [02:16] generative AI age. But cloud code didn't [02:19] change engineering with the agent [02:21] architecture alone. It's more than that. [02:23]  [02:23] What is claude code really made of? It [02:26] has three essential elements that [02:28] defines it. A powerful set of language [02:31] models that can call any tool in the [02:34] right agent loop. This is what makes [02:37] cloud code so incredible. You can't have [02:40] one of these. You can't have two of [02:41] these. You need all three. The [02:43] architecture is everything. Don't let [02:46] the benchmarks fool you. The performance [02:48] from the Cloud 4 series is not [02:50] detectable by the benchmarks. We'll [02:53] discuss that more in a moment. But you [02:55] put powerful LLMs like the Cloud 4 [02:57] series with a great set of bakedin tools [03:00] and the ability to connect to any MCP [03:03] server. But that's not it. You need the [03:05] agent architecture. You need the agent [03:07] loop so that the agent can operate in [03:09] the right environment and use the right [03:11] information to get the job done just [03:14] like you or I would. This is the [03:15] architecture behind cloud code. So how [03:18]  [03:18] has claude code changed engineering? [03:20] It's not just a tool. It's not an [03:22] assistant and it's more than a partner. [03:24] It's a new engineering primitive, right? [03:27] It's a fundamental building block of a [03:29] new class of software development. A new [03:32] primitive that lets you tap into agents [03:35] with a single prompt. That means more [03:38] compute at your fingertips at any time [03:41] at scale. It's a fundamental building [03:43] block. What does that mean exactly? [03:45] Cloud code is programmable. From any [03:48] terminal, you can call your powerful [03:51] agentic coding tool. This is massive. As [03:54] engineers, we need the Lego blocks to [03:57] solve the problem for our specific use [04:00]  [04:00] cases in our specific domains. A lot of [04:03] engineering products and tools miss [04:05] this. They're too opinionated. There's [04:07] too much thought. Speaking of the [04:09] terminal, Cloud Code was able to change [04:11] software engineering because it operates [04:14] in the highest leverage point for [04:16] engineers. It's not an accident that [04:18] it's in the terminal. This is where us [04:20] engineers have maximum control over the [04:23] flow of information. We trade off that [04:25] initial investment of understanding the [04:27] terminal to have massive impact with [04:30] minimal friction. It seems so obvious [04:33] now in retrospect that this is the [04:36] optimal place for an engineering agent. [04:38] We have to give shoutouts to the [04:40] original AI coding tools like Ader for [04:43] starting right in the terminal. And of [04:45] course, Claude Code and Enthropic [04:48] focused on real engineering. These [04:50]  [04:51] aren't toys. These aren't flashy demos. [04:54] They change engineering by relentlessly [04:56] focusing on true engineering workflows. [04:58] Right? Think, plan, build with plan mode [05:02] hooks to control and monitor. You can [05:05] parallelize your agent. And then of [05:07] course, it's programmable. This is a key [05:11] feature of true engineering. Can your [05:13] tool, can your work be composed? Is it [05:16] interoperable? Right? You can build your [05:18] own agentic systems with cloud code. And [05:20] once you start stacking these together, [05:22] I've only listed a few here. Right? [05:24] There are many, many more features. [05:25] These all help us engineers with our [05:27] boots on the ground solve real [05:29] engineering problems. It seems so [05:31] mind-blowing that no previous tool [05:34] really allowed us to tap into our [05:36] prompts in a reusable way until Cloud [05:38] Code. They did it right. They built [05:40] features for real engineering. It's not [05:43] just about features. It's not just about [05:44] calling tools. Of course, none of this [05:45]  [05:47] is possible without their models. And [05:49] something incredible happened. Starting [05:51] with the Sonnet 3.5 model. [05:53] unexplainable, [05:55] unttrackable emergent behavior inside of [05:58] that model that again doesn't show up in [06:01] benchmarks. I have a term for this [06:02] because I like to look out for this. [06:04] Okay, I call these benchmark ghosting [06:06] models. Their performance does not show [06:09] up in a benchmark. And you know, you can [06:11] see this, right? Open up artificial [06:13] analysis, look for sonnet, and just [06:15] search through this. You can see this is [06:18] not the quote unquote best model on [06:20] almost any benchmark. You can look for [06:23] Opus and you'll see the exact same [06:25] thing, right? By no means is this the [06:29] best model. Okay, but then why were we [06:32] able to do more with it than any other [06:34] model? This is because of emergent [06:36] behavior. Something has cracked inside [06:38] these models. Okay, they didn't just [06:40] pass benchmarks. They made benchmarks [06:43] irrelevant. Real world performance can [06:46] only be approximated by benchmarks, [06:49] right? their their proxies, their [06:51] shells, their corlary systems, right? [06:53] They don't equal true results, right? [06:56] So, I'm not saying benchmarks don't [06:57] matter, but models with emergent [06:59] behavior that understand, and this is [07:01] the important part, your context and [07:03] your intent is what matters. And from [07:07] sonnet 3.5 to now, and I imagine [07:09] whatever anthropic is cooking next, the [07:11] way they build their models encodes [07:14] intent. It encodes engineering intent. [07:17] This is an extremely unique property of [07:20] these models. An interesting question [07:22] you can ask is how can I find emergent [07:25] behaviors inside of models? And so far [07:29] my only answer for this is time. You [07:32] need to spend time with these models. [07:34] And oh boy, I know you and I, a lot of [07:38] engineers were spending a lot of time [07:40] with these models. So how else has claw [07:43] code changed engineering? It's brought [07:45]  [07:45] us all back to simplicity, right? As a [07:49] core principle. As soon as I heard this [07:51] from Boris, it completely made sense. [07:54] You can see it. You can feel it in the [07:56] tool, right? Simplicity is a property [07:59] and a feature. Okay? And I am worried [08:01] about this for the future of cloud code. [08:03] Every successful application grows. It [08:06] grows in complexity. It grows in [08:08] features. It slowly becomes something [08:11] that it wasn't. I hope that the claico [08:13] team, the anthropic team, they stick [08:16] with this property. If they don't, the [08:18] tool will lose this powerful property [08:22] that myself and other engineers uh seek [08:25] uh pretty much in everything that we we [08:27] do and and in and you know, every tool [08:29] that we use. Enthropic has this [08:31] beautiful principle um do the simple [08:34] thing first inside of principle a [08:36] coding. This is the first principle we [08:38] discuss and it is keep it simple stupid. [08:41] Right? That's our version of it. These [08:42] are all the same thing. Simple things [08:46] work. And not only do they work, they [08:48] work consistently. Also, I don't know if [08:51] you've heard the news, but the creators [08:53] of Cloud Code, Boris and Cat, are [08:55] apparently moving back over to [08:58] Anthropic. They were rumored to be [09:00] leaving. Now they're rumored to be [09:02] coming back uh from Cursor. This tells [09:04] me that whatever they saw at Cursor was [09:07] not good. Just to call it out here, [09:09] sometimes I still boot it up for the tab [09:11] model, but that's a great example of an [09:13] application that is no longer simple, [09:15] right? It was when they started, but now [09:17] it's not as simple. And that's not to [09:19] say that it's not a great useful tool. [09:21] But you can see the difference between [09:23] cloud code and many other tools, right? [09:25] There's no complexity. It's just the [09:27] context window. I said it long ago [09:30] as everyone was piping and jumping over [09:33] to rag. You want just the context [09:35] window. Don't add unnecessary [09:37] complexity. Let the model do what it [09:40] needs to with the right tools. Right? [09:42] Let it search just like you and I [09:44] search. Think about the tool you would [09:46] use. Great. Now, give the model the tool [09:50] you would use. Okay? At least to start. [09:52] All right? So, there's no complexity. [09:54] It's just a context window. No setup. [09:56] Uh, this is something that's really [09:57] powerful. A lot of us engineers, we [09:59] overthink things. We try to compare and [10:01] contrast all the time. Cloud code said [10:04] no. Sonnet, Opus, no setup. All right. [10:08] And then there's no friction. It's just [10:10] the prompt. I still to this day have [10:13] opened the application probably tens of [10:15] thousands of times. That sounds [10:16] ridiculous, but I love opening the [10:19] terminal, typing Claude, and this is all [10:22] you see, right? It's just this. It's an [10:26] input field, and your agent loads things [10:29] into its context window, and the LLM [10:30]  [10:31] drives decision-m. That's it, right? I [10:34] still love that to this day. All right. [10:37] Um, you know, the cloud code team, [10:38] they've cracked it. AI coding is not [10:40] enough. This is something that we have [10:41] talked about on the channel. I ran into [10:43] this issue very, very early on when I [10:45] was using Ader. Writing code is a [10:47] fraction of what engineering is. And [10:50] this is why vibe coding falls apart even [10:52] with powerful agents. Coding is not [10:54] enough. It's not just about generating [10:56] code. Engineering is about much more [10:58] than that. We needed a gentic coding and [11:01] now we have it. We needed something that [11:03] scales with the complexity of the [11:05] problems we face as engineers. The agent [11:08] does it and we can use it with agentic [11:12] coding. So last thing to call out here, [11:14] how has cloud code changed engineering? [11:17] It's infinitely scalable. Okay, solving [11:19] two problems at once, fire up multiple [11:21] parallel sub aents. Are you working on [11:23] multiple iterations, multiple problems [11:25] at the same time? Open up multiple cloud [11:27] code instances, right? Do you need your [11:30] own custom multi- aent system? Fire up [11:32] programmable mode, right? -p run it from [11:35] any terminal. Run it off device. Again, [11:38] it's programmable, right? It's a new [11:41] foundational unit of engineering. It's a [11:43] new engineering primitive. [11:46] Okay. So, let's talk about the future. [11:48] So, we know where we're at, right? We [11:50]  [11:50] have this incredible tool that pushes us [11:52] from AI coding into a coding. So, we [11:55] have to ask the question, what's next? [11:57] So, here are some predictions from the [11:58] edge from everything that I can see. We [12:00] talk about this on the channel. Go where [12:02] the ball will be, not where it is. One [12:05]  [12:05] of the trends happening right now, [12:07] you're seeing this if you're paying any [12:08] attention at all. Multi- aent systems, [12:11] not one claw, not two. We're talking [12:14] swarms working together in order running [12:17] in AI developer workflows, ADWs, [12:21] commonly known as agentic workflows. [12:23] Each agent specializes. You need that [12:26] context window focused on one problem [12:28] and then you hand off to another agent. [12:30] You see this inside of cloud code. You [12:32] can fire up sub agents. That's just the [12:34] beginning of what's possible. Together [12:36] they form systems more powerful than any [12:39] single mind. Okay? And I'm talking about [12:42] you and I. You know on the channel we've [12:44] we've run some systems that are doing so [12:47] much engineering work at one time that [12:49] it is is truly hard to follow everything [12:52] that's going on. This is where [12:53] observability and monitoring comes in. [12:55] We talked about agent observability in [12:57] our previous couple videos. We're going [12:59] to see this become more and more [13:00] important and we're going to continue to [13:02] see multi- aent systems get used and [13:05] built everywhere. All right. So, [13:08] dedicated agent environments to support [13:10] the scale and potential of the multi- [13:12] aent systems we're going to be operating [13:13] in. We need dedicated agent [13:15]  [13:16] environments. Okay. This is a big trend [13:18] and an easy bet to make. This is what [13:21] you want, right? As an investor of your [13:23] time, money, and attention, you want big [13:26] trends that are easy to bet on. And this [13:28] is one of them. Okay. So, you know, I [13:30] have, and others are starting to do this [13:32] as well, I have a dedicated box right [13:35] here. All I do in this Mac Mini, all I [13:39] do in this device is run agents. They [13:42] have full control over this device here. [13:44] We're going to be talking about [13:45] dedicated agent environments a lot more [13:48] on the channel. You can have physical [13:49] devices, cloud VMs, and there are even [13:52] services that are getting spun up from [13:55] nowhere. And one of these companies, I [13:57] can guarantee you, is going to become [13:58] the new versal for AI agents. This is a [14:02] big idea. Um, dedicated agent [14:04] environments are something that is going [14:06] to happen. It's starting to happen [14:08] already, right? You don't want your [14:09] agent running on your device, taking [14:11] over your device. This is great, but [14:12] this back and forth prompting with your [14:14] agent is going to be good for you [14:17] building these bigger systems. Okay, a [14:20] lot more to say on that on the channel. [14:21] Make sure you comment and subscribe so [14:23] you don't miss that and so you let the [14:25] algorithm know you're interested in [14:27] this. What's next? What does the future [14:29] have for us? What bets can we make as [14:31] engineers right now to get ahead of the [14:33] curve? Unbelievable automation. This is [14:36]  [14:36] not new, but the scale is going to be [14:39] new. I don't know if you've had this [14:40] experience, but I've gotten some [14:42] multi-agent systems up and running that [14:44] are so powerful, so complex, it's hard [14:46] for me to keep up with what I can do and [14:49] with what I can do with these new [14:51] systems. Okay, I'm starting to see few [14:54] groups of engineers running into this [14:55] problem as well, right? The scale is so [14:58] big. The workload, they're becoming so [15:01] massive. What it used to take teams [15:03] months will take minutes. will close the [15:06] loop and let the code write itself. [15:09] Closing the loop is a principle of AI [15:12] coding. You can see all the big labs [15:15] going crazy over this idea right now. [15:17] And frankly, any good agentic coding [15:20] engineer really focuses on this idea, [15:22] right? Don't just write a prompt. Write [15:24] a prompt and then say validate your work [15:27] with X. That creates a closed loop [15:29] system. I have something that can help [15:31] you understand that concept at the end [15:33] of this video. But the key idea here is [15:35] massive. We're going to have entire code [15:37] bases refactored while you sleep. Test [15:39] suites automatically generated [15:40] documentation that writes itself. This [15:42] is just the beginning of like the [15:43] automation that's that is coming and [15:46] that some engineers are starting to [15:47] crack. So here's a big one. This is an [15:50] important one. The engineering gap [15:52] continues to widen. There's a lot of [15:53]  [15:53] talk about the zero to 1x engineer, you [15:57] know, using tools like lovable. They are [15:59] able to do more than ever. That's great. [16:01] That's true. But there's a really [16:02] interesting gap between the 1 to 10x [16:05] engineer and the 0ero to 1x engineer [16:08] where they just stop. There's a point [16:10] where they can't build any bigger. They [16:13] can't build any more value because they [16:15] don't know what's going on. I do believe [16:17] that the gap will widen and then shrink [16:19] as the tools progress and as our agents [16:22] become that much more powerful. But [16:24] there's going to be a dark age here, [16:27] right? a a dark age where, you know, [16:29] senior plus level engineers, mid-level [16:31] plus engineers using these tools, your [16:33] 10xers on your team, in your company, [16:36] the difference between them and then, [16:37] you know, your mid and below engineers, [16:40] your noobs, your vibe coders, it's going [16:42] to be mindblowingly massive. And it's [16:45] because when they watch an Indy Dev Dan [16:47] video, they understand what's going on [16:50] underneath, right? They know that when I [16:51] gloss over, you know, certain syntax or [16:54] the way I organize functions or the way [16:56] I organize the codebase, the runtime of [16:58] a specific method, you know, that's a [17:00] great example, right? They know that you [17:02] can prompt and discuss, you know, [17:04] logarithmic runtime of a specific piece [17:07] of code and have a discussion about [17:09] optimizing it, moving it. There are many [17:11] core engineering ideas like runtime [17:15] complexity, low-level architecture, why [17:18] we use certain frameworks, why you use [17:20] certain tools, tool mastery, right? Even [17:23] things like understanding what the [17:24] terminal can do and how you can [17:26] customize and modify your terminal. [17:27] There are tons of examples of beginner [17:29] engineers, they will just never learn [17:32] this stuff. Some of you guys will, some [17:33] of you guys are really smart and you'll [17:35] use these tools to learn instead of just [17:37] use the tools to build, right? There's a [17:39] big difference there. A lot of vibe [17:40] coders are just building. They're not [17:42] learning. But anyway, I don't want to [17:44] harp on this one too much. I just want [17:45] to mention that there is still time to [17:47] choose which side you're on. Use these [17:49] tools to learn. You're mid senior level [17:51] plus engineer. Don't become an old dog. [17:53] Keep investing in learning new [17:56] engineering, right? Learning the [17:57] generative AI way to do things. Okay? [18:00] Because it's not the same, right? This [18:02] is a new skill. AI coding is a new [18:04] skill. Agentic coding is a new skill, [18:06] right? The way you prompt these systems [18:09] continually evolves, right? The way you [18:12] add context continually evolves. I don't [18:15] care if you call it prompt engineering [18:16] or context engineering. It's going to [18:19] keep changing and evolving. All right? [18:21] So, take some time, always invest in [18:23] your tool. Always keep learning, right? [18:25] Because the engineering gap is going to [18:27] widen massively before it shrinks again. [18:31] And lastly, this is really important. [18:32]  [18:34] This is a great call out for engineers [18:36] and teams looking for that next product. [18:39] Agents are going viral. Okay, they're [18:41] going to go viral over these next couple [18:43] years. Cloud code is the agent for [18:45] engineering, but there are hundreds of [18:48] domains where agents don't exist yet, [18:50] but where they can be created and [18:52] deployed. You know what that smells [18:54] like? What do we smell there? That's [18:56] called opportunity. Okay, if you're a [18:59] builder, if you're a creator and you're [19:01] in one of these domains, right, you do [19:03] want a domain advantage. If you're in [19:05] one of these domains, right, or any [19:07] domain, um the amount of of TAM, total [19:12] addressable market ready for disruption [19:14] for you, for your team, for your [19:16] company. This is a massive opportunity. [19:19] agents go viral and of course you know [19:22] it's natural that the first agent right [19:24] the best piece of technology would [19:26] emerge for the technology builders which [19:28] is you and I agents are going viral this [19:31] is a big opportunity uh this is a future [19:34] direction of where agents are going of [19:36] where agentic coding is going so on and [19:37] so forth all right the evidence is super [19:39] clear this channel is one of the first [19:41] to cover cloud code before all the hype [19:43] before you know everyone in their mom [19:46] starts using you know cloud code we [19:48] covered it first. This is the place to [19:50] be for agent coding on the edge for [19:53] really just that next phase of [19:55] engineering. So again, I don't know how [19:56] many times I can see TA in one video, [19:58] but comment, subscribe, like, you know [20:00]  [20:00] what to do. Tell the algorithm you're [20:01] interested. All right, we were here [20:02] since the beginning and we're going to [20:03] be here until the end. Okay, we're in [20:06] the age of agents, okay? It's phase two. [20:09] After decades of failed AI promises, the [20:11] agent architecture has delivered. All [20:14] right, so take action. Couple call outs [20:16] for you, you know, as a thank you for [20:18] making it to the end of the video, for [20:19] sticking around. I always aim to provide [20:21] value for engineers here every single [20:24] week. Master Claw Code. Everyone else is [20:27] copying cloud code. All right, you saw [20:28] it with the CodeCli. You saw it with the [20:30] Gemini CLI. You see it with open source. [20:32] It's fine. Copying is great. This is how [20:34] we grow and improve, right? There are [20:36] copycats everywhere. First, you copy, [20:39] then you innovate. Whatever. Right now, [20:41] this is the tool to master. Okay. Scale [20:43] up your compute. More prompts, better [20:45] prompts than more agents. If you can't [20:48] use one cloud code instance, getting an [20:51] agent device makes no sense for you. [20:53] Scaling up more agents, using sub [20:54] agents, it makes no sense for you. Okay? [20:56] So, step up one step at a time. Scale [20:59] your compute. More prompts, better [21:00] prompts than more agents. All right? You [21:03] can do a lot more with the right prompt [21:05] than you think. All right? And I'm [21:06] looking at all of you who think your [21:08] codebase is too big. Okay? No, you just [21:11] haven't written the right prompts. All [21:13] right? solve bigger problems. Right? On [21:14] that same note, keep your agents running [21:16] longer and then longer. Okay? These [21:19] things can run for tens of minutes, half [21:21] an hour, and if you set it up right, [21:23] they can run for hours. Agents, okay? [21:27] Solving problems, building things, doing [21:29] research. It's happening right now. All [21:31] right. So, that's that. Uh, focus on [21:34] principles, not tools, not models. I [21:36] know some of you that have been with the [21:37] channel, you know, forgive me. Um, but [21:40] it's important to keep plugging for [21:41] engineers before the next big course [21:43] hits. If you want to get a asymmetric [21:46]  [21:46] advantage on your time, I definitely [21:48] recommend you check out principled AI [21:49] coding. This is my take on how to master [21:52] the principles of AI coding. AI coding [21:54] came first. We're now agentic coding. [21:56] All the principles of AI coding directly [21:58] apply to agentic coding. Okay, agentic [22:01] coding is a superset of AI coding. You [22:04] want to focus on principles, not tools. [22:06] All right? and you want to master the [22:07] big three, that's going to show up in [22:09] every tool, in every agent, in every [22:11] multi- aent system context model prompt. [22:14] I'm not going to pitch this for too much [22:15] longer because the next phase 2 agent [22:18] coding course is coming. I am killing [22:20] the limited time discount after this [22:22] week. All right, this goes up to the [22:23] full price. This is risk-free. There is [22:25] a no questions asked refund before [22:27] lesson 4. If you get in here, if you [22:29] think it's outdated, if you can't make [22:30] the connection that it's about [22:32] principles, not tools, not models, [22:34] that's fine. Let me know. I'll refund [22:36] you in full. The next course is coming [22:38] focused on agentic coding and most [22:41] importantly focused on you. There's so [22:43] much work that you're doing now that you [22:45] don't need to be doing. The next course [22:47] we're going to tackle that problem head [22:49] on with of course the brand new [22:52] engineering primitive claw code. By the [22:54] way, anyone that has taken principal a [22:57] coding will receive a massive discount [22:58] on the next agentic coding course. a [23:01] little extra bonus and thank you for [23:04] everyone that's taken the course, [23:05] everyone that's trusted me with their [23:07] time and attention. Thousands of [23:08] engineers have been here and have gotten [23:10] massive value out of principal AI [23:12] coding. We discuss a lot of the big [23:14] ideas that are now popular. You know, [23:16] when we put this out, they were a lot [23:18] less popular. I'll just say it that way. [23:20] Plan-based coding, right? Specs, [23:22] programmability, and we talk about [23:24] closing the loop. This idea is [23:26] everything. This is in lesson seven. Let [23:28] the code write itself. That's that, [23:30] right? So, focus on principles, not [23:32] tools, not models. Both of these will [23:34] change. These never change. All right? [23:36] Principles never change. Subscribe, [23:38] comment, let me know where you're taking [23:40] your agentic development. You know where [23:42] to find me every single Monday. Thanks [23:45] so much for watching. Stay focused and [23:48] keep building.