[00:00]  [00:00] Welcome back engineers. Indie Dev Dan here. Imagine starting your day. You of course open up the terminal. You fire up [00:06] Claude Code. Then you kick off a single prompt/cook that does the work it used to take you [00:13] hours in minutes. You're able to accomplish this with Claude Code sub [00:18] aents. You've created workflows of specialized agents that do one thing and [00:24] do it extraordinarily well. You can see I have this agent called meta agent. My [00:30] agents are building my agents. Code is a commodity. Your fine-tuned prompts can [00:36] be valuable. And now your cloud code sub aents can yield extreme value for your [00:42] engineering if you know how to avoid the big two mistakes engineers are making [00:48] with sub aents. In this video, we're going to break down how to build effective cloud code sub aents. We'll of [00:55] course use this powerful meta agent to build new agents. But before we get there, sub agents have serious [01:01] trade-offs and pitfalls you should know about so you don't waste your engineering time and tokens. Let's [01:08] understand how to take our agentic coding to the next level with clawed [01:13] code sub aents. [01:15]  [01:23] So, first things first, what are claw code sub aents? I can almost guarantee you sub agents don't work like you think [01:31] they work. Let me explain. Here's what the flow of claw code agents look like end to end. Starts out with your prompt. [01:38] Your primary agent then prompts your sub agents. Your sub agents then do their [01:43] work autonomously and then this is important. They report back to your [01:48] primary agent and your primary agent reports back to you. The flow of [01:54] information here is absolutely critical. You prompt your primary agent and then [01:59] your primary agent prompts individual sub aents based on your original prompt. [02:05] Your sub agents respond not to you, they respond to your primary agent. Okay? [02:12] Many engineers are going to miss this fact and this changes the way you write [02:17] your sub agent prompts. Let's break down exactly what claude code sub agents look [02:23] like. So inside this codebase, we have a simple hello world agent prompt. You can [02:29] of course see this is operating inside of the brand new agents directory. We have a new agentic directory to focus [02:36] on. So, we'll get to the important meta agent in a moment. Let's start simple and understand what sub aent prompts [02:44] look like. We'll open up a new shell here. Fire up claude in yellow mode. And you'll notice here in the description, [02:51] if they say hi claude or high CC or high claude code, use this agent. Hi CC. And [02:57] now cloud code immediately finds this agent, right? It finds the description for this agent and kicks it off. You [03:03] have your agent name. This is its unique ID. The description, which is very important. This communicates to your [03:10] primary agent when it should call this agent tools. So, you can specify specific tools available. [03:16] Sub agent complete and the color which you can see right here. You can see we have a nice formatted response there. That natural [03:22] language text to speech by the way that's set up with cloud code hooks on the stop event. But if we look at this [03:28] format, there's something really important here. And we're coming up on the first big mistake engineers are [03:34] making when using clutter code sub aents. If we open up this prompt here, you can see we have a classic markdown [03:39] format, purpose and report. The first mistake engineers make is not [03:45] understanding that what you're writing here is the system prompt of your sub [03:51] agent. Okay? This is not the prompt for your agent. Okay? It's the system [03:56] prompt. This is important. It might not seem like an important detail, but it changes the way you write the prompt and [04:02] it changes what information is available. That's a big mistake. But even bigger is this. Notice how I have [04:08] this section here. And remember in our diagram here, remember who your sub agents are responding to. It's not you. [04:14] It's your primary agent. Okay? This report, this response format is going to be really important. You can see here [04:20] I'm explicitly having the sub agent communicate to the primary agent. I'm saying Claude, respond to the user with [04:27] this message. And guess what happened? Look at the response. Hi there. How can I help you? Did you know Nvidia blah [04:33] blah blah blah blah. Right? We had it research some random uh tech news. Right? This is the sub agent prompt [04:40] format. We have variable declaration at the top. The cracked cloud code team is going to tweak, improve, add to these as [04:48] time goes on. They're probably going to add the model here at some point. We have our system prompt, right? And you [04:54] can see this right in the docs. If you don't believe me, you can always just open up the docs, search system, and you can see what we're actually writing here [05:01] is the system prompt. To be super clear, this is not the user prompt. Okay, when you're writing uh let's open up the [05:08] prime command. When we have something like this slashp prime, this runs right [05:13] into our primary agent. This is a prompt, right? A user prompt that goes right into the context window of our [05:21] primary agent. Okay, our agents directory is very different. This is a system prompt. We're defining the top [05:27] level functionality. These prompts are going to look similar, but it's important to delineate, right? You can [05:33] pass variables into this. This is a system prompt. This is not what triggers [05:38] what's actually done. And so, you know, again, just to bring this up, if you understand this, you're going to perform [05:43] very well with your sub agents, and you're going to be avoiding the top two mistakes engineers make with cloud code [05:49] sub agents. You don't prompt your sub agents. You can write a prompt for your [05:55] primary agent to prompt your sub agents, but you're communicating with your primary cloud code agent, right? The top [06:01] level agent. We'll call this the primary agent. It's cloud code that prompts your sub agents, right? It is delegating. You [06:09] really want to be thinking about your cloud code sub aents as tools of delegation for your primary agent. And [06:16] this is why the big three is so important. Okay, we we cover this all the time on the channel. This isn't [06:23] going away anytime soon. In fact, it's only going to become more important as we scale up our agent coding to multi- [06:29] aent systems, right? Context, model, prompt, and specifically the flow of the [06:36] context, model, and prompt between different agents. Okay, this is super important. Okay, so I think you get the [06:42] point. I don't need to keep harping on this. This is just really important. If you make these mistakes, this will eventually go ary, right? especially as [06:49] you start scaling up what you can do with chains of sub agents, [06:50]  [06:59] right? So, we're just getting started here. You can chain the call and responses and call and responses, right? [07:05] It's funny that we started out prompt chaining years ago and now we're still prompt chaining. We're just prompt [07:10] chaining with bigger compositional units. You and I, the user, prompt the primary agent. They can then run tasks [07:17] and then based on the prompt they come back into the primary agent and you can have your agent keep cooking, right? It [07:23] can keep doing important work for you. So you can fire off another set of sub aents. And so this is the true flow. [07:29] Your sub aents are responding to your primary agent. And if you're doing powerful multi- aent orchestration, [07:35] which you will be pretty soon here, if you're watching the Dev Dan channel, make sure you're subscribed and you comment to stay plugged in to key [07:42] engineering information like this. You can tell um I don't just copy and paste [07:47] the documentation. Um you know, everyone's using this. I think cool, that's good. Use this. But um read the [07:55] documentation, guys. Like really read through this stuff. It's important. Okay? This is the most important [08:01] technology of the year, probably over the next few years, right? Agents are how you win as an engineer. Understand [08:07] what they really do, right? Don't offload all the cognitive work to your agents, right? understand the most [08:13] important technology. Okay? And to be super clear, there's nothing more important right now than agents. And the [08:19] leading agent is Claude Code. If you've been following the channel, you already know this. You've been listening to me [08:24] glaze the team and glaze the the product. You know, really communicate the value of this, right? But it but [08:30] it's all for a reason. I focus on the signal that every engineer has a superpower. Every engineer is super [08:35] super good. They're cracked at something. One of my key abilities is to focus on the signal and cancel out the [08:42] noise. Okay? I can focus I can focus directly on the signal of where the [08:48] valuable information is. Truly, there's no other way I could show up here for [08:53] you every week with something valuable if I wasn't constantly just obsessed and passionate about finding the signal. [08:59] Okay, this, you know, again, this is super powerful. Copy it, throw it into an LLM, but don't offload deep [09:05] understanding, right? You're basically just vibe coding then. Okay. Deeply understand your tools so that you can do [09:11] more, better, faster, cheaper, so on and so forth. Okay. Anyway, where were we? Um, we were talking about chaining. Yes. [09:17] So, this is super important, right? If you want to scale up, you need to understand the information flow. Okay. [09:24] We're not just prompting a chat interface anymore. We're not just dealing with one context model prompt [09:29] agent system. We're dealing with multi- aent systems. Okay? And there's a reason I put out that multi- aent observability [09:35] video. I knew this was coming. It's here. Okay, multi- aent systems are here. The best engineers, the most [09:42] cracked seniors. We're scaling up hard. Okay, compute, compute, compute, [09:47] compute. And you can see it here. This is just a simple flow, right? You prompt your agent, hit fire sub aents, collect [09:53] results. Okay, then the next step in that custom/comand is going to be great, collect the results, fire off more sub [10:00] aents that, you know, create a concrete solution. This is all fantastic. Let's actually use this. I did mention I'm [10:06] going to share my meta agent with you. I've built uh 50 probably 100 plus agents already, which is kind of crazy [10:12] to say, but it's all thanks to this meta agent, right? As soon as you get access to a new feature, figure out how you can [10:18] scale it up. Oftent times, you know, with Genai, you build a meta version of that, right? The thing that builds the [10:24]  [10:24] thing. What are we going to do here? Let's just [10:30] delete a bunch of stuff. Okay. If this causes you pain, you know, if deleting [10:35] causes you pain, you probably aren't deleting enough. Uh, so let's get rid of this. Let's get rid of this. And, uh, [10:42] let's get rid of this as well. Let's create new agents with our meta agent. And so, to cue this up, you know, a big [10:49] issue I see in the engineering space, in the Gen AI ecosystem, is that I'm seeing a lot of engineers uh, using technology [10:57] to create solutions for problems that don't exist. Noobs and beginners, they start with the technology and work [11:03] backward. If you want to become a real engineer, if you want to continue being a valuable engineer in the generative AI [11:09] age, work the other way. Work the right way. Work the way that product builders think. You have a problem first. Next [11:15] comes a solution and then the tech comes third. Okay? Problem, solution, tech. [11:21] Okay? So, what do I mean by that? Let me show you a concrete example. Let's use our meta agent to solve a real problem. [11:26] Let's start at the top, right? What's the problem? When I'm a magenta coding at scale, I lose track of what some [11:31] agents have done. Okay. Problem statement. Solution. Add text to speech to my agents so they notify me when [11:38] they're done and more importantly what they've done. Okay. So now we have a problem and a solution. Now let's use [11:44] the technology. Okay. Only after you have a problem and solution should you move the technology. So technology we [11:49] can use cloud code sub aents. I have a meta agent here that I can use to build up a new textto-spech agent that [11:57] communicates what was done. Okay, fantastic. Order matters problem solution technology. So inside of [12:03] MCP.json.sample, we have a setup for the 11 labs MCP [12:09] server. I have this configured in my.json here. This is get ignored because of course we have environment variable information here. First I want [12:16] to understand what my agent can do. So I'm going to run all tools. All tools looks like this. It's a simple reusable [12:22] prompt. List all available tools in your system prompt. I want bullet points. I want TypeScript function signature [12:28] format. This is going to allow us to understand the tools available to us. And specifically, I want to see the 11 [12:35] Labs tools. Great. So, here are all the available tools. I'm just going to copy these out so I can quickly search. I need two things. Text speech and we [12:43] probably need some way to play, right? So, I'm going to search text forwardlooking speech. There it is. Text to speech. So, [12:50] I'm just going to paste that here. And we also want to find a play. There it is. Play audio. Great. Okay. So, we have [12:57] these two methods that we can use. And we actually want the entire definition so we can know the exact parameters that [13:03] we're playing with. Right. Let's paste this all in mode back to text format [13:08] real quick. Great. Now, let's go ahead and just run these. Right. So, this is [13:13] in our primary agents context window. I'm just going to say 11 labs. I've [13:18] completed. Next, we can and I think we have voice ID here. Let me quickly copy [13:24] one of my favorite 11 labs voice IDs. Voice ID. Just going to be super clear in the prompt. Output directory. Right. [13:31] Output. Great. Output directory. Output to pwd, which is current working directory/output. [13:36] I'm going to have cloud code opus fire off this tool here. And all I'm doing here is validating the workflow. I'm [13:42] going to encode into an agent. So, text to speech. Great. Save the file. And now we want to run. All set and ready for your next step. [13:48] Great. Now we're going to run play audio. And I should just be able to say play audio because all the context is loaded. Um, [13:55] our agent is prime. Okay, that was good. I was talking over it. So I'm going to run it again. Run again. I've completed XYZ. Next weekend ABC. [14:02] Great. So we can see that we have text to speech working. We now have full capability to have our agents communicate with us via a sub agent. [14:09] Okay. So fantastic. So now we can crank open our powerful metaprompt. Okay. So [14:14] now that we know the workflow and the work that we want done, we can build a new agent that encapsulates this work. [14:20] So we can open this up and we can see exactly what our meta agent is doing. It [14:26] has a system prompt that details how to create a new agent, right? It's doing all this work in the isolated context [14:33] window. And so I'll fast forward through this. I'm going to type up the prompt right here. So this is what it's going to look like, right? Build a new sub [14:39] agent. So I'm asking cloud code to build the agent. And you can see here uh generate a new complete cloud drive sub [14:45] aent configuration file you from a user's description. Okay. So use this to [14:50] create new agents proactively. So we're using the information dense keyword [14:55] encoded by anthropic and that we should probably make this uppercase just to make it more dramatic. When a user asks you to create a new sub aent. Okay. So [15:03] we want to make sure that we have that language inside of our prompt. Build a new sub aent. Great. We're defining when [15:09] it's proactively triggered based on our conversation so far. Our agents will have blah blah blah blah blah. I'm just [15:15] detailing exactly the flow that we went through. Okay. Get the current working directory. Text to speech. Play. Great. [15:20] So again, copy this. Let's fire this off. And now you're going to see the description of our meta agent here. Get [15:27] activated. This is very important. You need your description to properly set up when your agent should call a specific [15:34] sub aent. So you can see cloud code is thinking about this. it knows and now it's going to use the sub agent. So, [15:39] couple key pieces inside of this prompt. I'm not just having this build on zero information. I'm repooling the cloud [15:47] code documentation live. Okay, I want the most recent updated AI documentation. viewers of the channel, [15:53] you know that I like to place this in AI docs, but there's a more powerful way to do this where inside of AI docs, you [15:59] just place a readme and then on the fly you have, you know, a prompt or now a [16:04] sub agent pull in live documentation with some type of refresh command. And [16:09] so you can see we have a brand new agent generated there. Let's go ahead and understand what's happened. Great. So through tool uses, our meta agent [16:16] successfully created now wants to read and verify. So this is great. So, our reasoning model is double-checking the [16:22] work. It's read the file and now it exists. All set and ready for the next step. [16:28] Let's go ahead and check it out. This is a great summary. Voice proactive output [16:33] autoplay. Looks good. Let's go ahead and look at our new agent. You can see it's in the exact format as we asked. [16:39] Fantastic. So, we can see here, you know, always review. Every word must add value. That's great. I like that line. [16:45] No pleasant trees. Yep. Exactly. I'm going to add a couple of things, right? So, variables, username, and what else [16:52] we're going to do here? I want just one sentence. Uh, these can be quite long. A concise one sentence looks great. I'm [17:00] going to make a couple tweaks here specifically to the description. This determines when your primary agent is [17:06] going to call your sub agent. Cloud code has this IDK, this information keyword that they mention um proactively, right? [17:14] They even have a little section for it. Use proactively or must be used. What we can do here is something a little bit [17:20] extra, right? You noticed in my hello agent, hello world agent, I like to have [17:25] these concrete tags or these concrete triggers for my sub agents. So if they [17:31] say X, Y, or Z, use this agent. So I'm basically just going to reuse this pattern. Frankly, I should encode this [17:37] into my meta agent. I'm just going to add this here, right? If they say TTS, [17:43] TTS summary, use this agent. um review user prompt given to you a concise [17:51] summary of what it does. By the way, um one of the big reasons I'm using cursor still is for writing prompts. It's great [17:57] for that tab completion. I also want to add one thing here. So, coming full circle here, remember that if we go back [18:03] to our basic flow here, it's your primary agent that prompts your sub agent. What your primary agent can see [18:11] and has access to is this description, right? This is how it knows when to call [18:16] any given sub agent you have. So you really want to leverage the description and tell your topable agent how to [18:22] prompt this agent. When you prompt this agent, describe exactly what you want [18:30] them to communicate to the user. And I'm going to add even more detail here. I'm [18:36] going to say, remember, and again, this is something that I really just need to encode in my meta agent. Um remember [18:42] this agent has no context any questions conversations [18:47] between you and the user and something I like to do to increase prompt adherence [18:53] um anthropic has another information dense keyword that you can use it is this so important colon I want to be [18:59] absolutely clear with this agent do these following things right we want a concise summary of what was done and [19:05] also I want to add one more here best practices important run only bash pwd [19:12] and the 11 labs mcbp tools. Don't use any other tools. Base your response. [19:18] Exactly. Okay, let's fire up another claw instance. We'll go ahead and just use sonic for this one. What does this [19:25] codebase do? Use tts summary. After we add details to when this should be [19:32] called, after we add instructions to the system prompt for our work completion [19:38] summary sub agent, we now have an operational agent that can quickly summarize in natural language for us [19:45] anywhere, anytime on any piece of work. Right? This is the beauty of agents and reusable prompts. Now we have this [19:51] problem solved for good and we can reuse it and improve it when we need to. codebase has been analyzed and now we're [19:57] getting text to speech structure, text to speech response. There it is. There's an input prompt. This codebase demonstrates Claude code [20:03] hooks mastery with all six life cycle events implemented for deterministic control featuring security filtering, [20:10] intelligent TTS feedback, automatic JSON logging, and UV single file [20:16] architecture. Next step, explore specific hook implementations or test the security filtering functionality. [20:23] Nice. Okay, so that looked good or that sounded good rather. You can see here there is work to be done here. That was [20:28] still longer than I wanted it to be. If we open up logs, thanks to cloud code [20:34] hooks, we are recording all the conversation that just happened. So, we can do something really cool. If we want to, we can dive in and actually see our [20:41] top level agent prompting our sub agent and our sub agent prompting the response [20:46] back to our top level agent. I'll leave that up to you after you finish watching this video. Run this. fire off the hello [20:51] world agent and the meta agent so you can really understand what the flow of information is between multi- aent [20:58]  [20:58] systems inside of cloud code. [21:04] So the benefits are pretty straightforward, right? Cloud code engineers said it themselves. Context preservation. This is both a benefit and [21:10] an issue. We'll talk about how this is an issue in a moment, but each sub agent operates in its own context, preventing [21:16] pollution of the main conversation. So this is powerful. We are booting up fresh agent instances for every one of [21:24] these tasks that we have for our natural language text to speech for our meta agent. They all have their own isolated [21:30] context window. This is very powerful. On the channel, we're going to talk more about how you can use this to scale [21:36] agents across your large complex code bases. You could already do this with [21:41] sub aents, but now you can do it even better with specialized sub aents. All right, so you get to save your context [21:48] window. This is a big idea that's going to come back up over and over again until we get those two 5 million plus [21:55] context windows. You know, I can tell you those aren't coming uh anytime soon as far as I can see. I would love to be wrong about that. Specialized agent [22:01] expertise. We can of course fine-tune the instructions and the tools. So, you [22:07] know, you can see this here for our text to speech agent. You can see we wrote a nice rich description on not only when [22:13] to trigger this, but um we're giving our top level agent instructions on how to prompt this. Okay, a lot of engineers [22:20] are going to miss this. Don't be one of them. You can instruct how exactly you want the prompt to flow in here in the [22:26] description. Reusability. This is a classic one. By storing this inside your repository, you can build agents for [22:33] your codebase. There's a powerful way we're going to discuss on the channel to use a meta agent to build specialized [22:40] localized agents that excel at operating specific parts of your large codebase. [22:46] Again, subscribe, comment, all that good stuff so you don't miss out on future valuable information like this. Flexible [22:52] permissions. You can lock down the tools your agent can call. That's fantastic. Obviously, if you're in YOLO mode, you have to be more explicit about what [22:59] tools can run, which is why I have this I added this important best practice here. But that's that. So, these are the [23:05] kind of four key benefits that Enthropic lists directly here. I think these are all true. There are a couple hidden [23:10] benefits as well. You get focused agents. All right? And you know, the cloud code team does mention this, but [23:16] you can really take this far, right? Just like booting up a fresh agent with a single prompt, when you use cloud code [23:22] sub agents, the agent is fresh. It only knows what your primary agent tells it. [23:27] That means it's less likely to make mistakes given that you design a good system prompt. Why is that? It's because [23:33] your agent is focused on one thing. Just like a focus engineer, when you're focused on one thing, you perform [23:38] better. Full stop. Another hidden benefit of cloud code sub aents is simple multi- aent orchestration. And [23:45] this is something that I'm most excited for with custom slashcomands combined with cloud code hooks combined with sub [23:52] aents right just kind of stacking up these powerful features you can build powerful [23:57] yet simple multi- aent systems. So you know as a concrete example we have this [24:03] in our commands we have this classic prime command and we can easily improve this right. So now we can have prime [24:09] tts. So say I want to kick off prime. I can say when you finish run the TTS [24:15] summary agent the user know you're ready to build. I already have uh cloud code [24:21] hooks with text to speech. We did this in a previous video. I'll link that in the description if you're interested. But we can of course you know run this [24:28] now in a fresh instance. We can run prime tts. And now when this finishes we're going to run right we're going to [24:34] chain text to speech summary agent at the end. There it is. And so here's a summary. It wrote the text to speech. So [24:41] we have the audio file code hooks mastery project with complete coverage of all six hook life cycle [24:46] events. There you go. So it's ready to go. So if you open up that that summary there, control E. You can see cloud code analyze hooks mastery blah blah blah [24:52] blah blah. So it's letting us know that it is complete. You know, we were able to guide our primary agents prompt to [24:58] our sub agent right here. Right? When you finish, run the TTS summary agent and let the user know you're ready to [25:05] build. So this is another hidden benefit. Right? we improve our multi- aent orchestration. Okay. And so another [25:11] pro and con is prompt delegation. So again, this is kind of on the line. You're delegating your prompts to the [25:17] primary agent oftent times just like you saw here and just like you saw in the work completion summary agent right in [25:23] the description. This means you have to do a little bit more work guiding your primary agent to call your sub agent [25:29] properly. This is powerful though. It's still good. We are offloading work, right? We're encoding powerful [25:35] engineering practices into our prompts and now into our sub agents. So all in all, it's good. So what are the issues [25:40] of this? Right? The opposite of context preservation is that and and you know this was a great example because you [25:46] kind of saw that you need to be super clear to your sub agents and to your primary agent what you're passing in to [25:52] the sub agent because it doesn't have any previous context. By definition, every sub aent having its own context [25:58] means that there is no context history. It doesn't have the rich context that your primary agent has. It has only what [26:05] your primary agent prompts it with. This is the equivalent just to make it ultra clear. This is like firing up claude in [26:13] print mode, you know, whatever. You can run yolo or dangerous blah blah blah. And don't run this by the way if you [26:18] don't know what you're doing. Uh this will run any command. We're starting to see in the industry uh yolo mode coders [26:25] are getting cooked by this command. So be really careful. Um, but this runs the following, right? So, it's basically [26:31] saying call work completion summary agent and then you're passing in one [26:37] prompt. Okay, this is what your primary agent is doing when it's calling the sub [26:42] agents. It's it's literally like it's you calling a oneshot prompt to the sub agent. Okay, there's no context. This is [26:49] a problem, right? It's a problem and it's a benefit, right? It's the it's the opposite side of the coin of context [26:54] preservation. Another big issue, these sub aents are hard to debug. You can see [27:00] every time we've run one of these, right? If we run high CC, even with this simple prompt, we have no idea what's [27:06] going on here. We'll get the tool calls, which is super super nice. But the actual workflows, the prompts, the full [27:12] parameters for every tool call, we don't get these. And this is by design, but it also makes these harder to debug and [27:19] understand what's going on. Right? So, another big issue here is decision overload. As you start scaling up the [27:25] number of agents you have, it's going to be harder and harder for your agent to know which one to call. Sub agent complete. [27:31] Okay, commands are a bit different. Although, you know, you the engineer might forget all the commands that you have, right? You just might start [27:37] forgetting all these commands, right? All the powerful commands you've built. Agents are a little different because based on the description and based on [27:44] the number of agents you have, your primary agent might get confused here. Okay, so this is important. You really [27:49] want to be keeping track of your agents. Otherwise, it'll come back to bite you and you're going to kick off these agents when you don't want to. As a [27:56] solution, you really want to be clear about when to call your sub agents with the description variable. This is the [28:02] most important variable right next to the name. Two remaining issues here. Dependency coupling is going to be a problem here. So, once you start setting [28:08] up prompts, primary agent, reusable prompts or custom slash commands, and once these are calling out your sub [28:15] agents, which this is how you, you know, start scaling up into multi- aent systems. Once you get that going, it's going to be hard. Again, back to [28:21] debugging. It's going to be hard to understand what's going on. You're going to have dependency coupling. Inevitably, [28:26] you're going to have an agent depend on output from another agent, depend on the format of the specific response from [28:31] another agent, on and on and on. And then one day, you're going to need to change something to improve it or to [28:36] ship something new, whatever. You're going to change the planner agent right here, and it's going to ruin everything [28:42] else because one thing changed. We're already operating in nondeterministic systems. When that one thing changes, it [28:48] could blow up everything else. Okay, so this is another problem with sub aents. As you start scaling them up, keep your eye on this. Try to keep them separate. [28:55] Try to keep them in isolated workflows. Don't overload your sub aent chain. [29:00] Okay. And then last thing, and this is just kind of a request on my side, even though it is literally counterintuitive [29:06] to what I was just saying, you cannot call sub aents in your sub agents. Okay? [29:12] Probably for all the reasons that I just mentioned. You know, it would be cool if we had, you know, kind of like dangerous [29:18] um sub agent true, right? So that inside of this agent or, you know, it's [29:23] probably like sub sub aent true. So that inside of this agent, we enable this dangerous powerful setting of calling [29:31] sub aents inside of sub aents. So this is me just being picky. That's not actually a real issue, but it's important to note that, you know, you [29:37] can't call sub aents in your sub aents, at least not yet. That's me being hopeful. So this is a very powerful [29:43] feature. We have quite a few more ideas to explore here with the combination of agents and custom slash commands aka [29:49] reusable prompts. Remember that perspective matters as you start scaling up your multi- aent system. Right? The [29:56] flow of the big three context, model, and prompt matter more than ever and [30:01] more and more as you scale up the number of agents who have shipping work on your behalf. There's a reason why it's a [30:08] principle of AI coding. As usual, link in the description if you want to learn the other principles of a coding that [30:13] will help you differentiate what you can do with agent coding. And I'll go ahead and bring back the other uh prompts that [30:19] I had here just for fun. But the meta agent is going to be here available to you. Link in the description. I'm going [30:25] to add these to the cloud code hooks mastery codebase. If you made it to the end, be sure to like, subscribe, and [30:31] comment your thoughts. No matter what, stay focused and keep building.