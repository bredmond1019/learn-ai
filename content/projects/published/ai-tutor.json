{
  "slug": "ai-tutor",
  "title": "AI Personal Tutor",
  "description": "Multi-agent research system that creates personalized learning experiences using MCP orchestration, achieving real-time knowledge synthesis from diverse sources with interactive visualizations.",
  "longDescription": "Engineered an intelligent tutoring system that transforms how people learn complex topics by orchestrating specialized AI agents through the Model Context Protocol (MCP). This project represents a synthesis of educational pedagogy and cutting-edge AI engineering, creating personalized learning paths that adapt to individual experience levels.\n\nThe system demonstrates advanced agent coordination, where multiple specialized agents work in parallel to research topics, extract key concepts, build knowledge graphs, and generate tailored summaries. Each component is designed with educational principles in mind, ensuring learners receive structured, comprehensible content that builds upon their existing knowledge.\n\nBeyond its technical achievements, the AI Personal Tutor serves as a comprehensive example of production-ready agent orchestration, complete with real-time progress tracking, cloud storage integration, and a modern web interface that makes complex AI interactions accessible to non-technical users.",
  "tags": ["Python", "FastAPI", "MCP", "AI Agents", "Education", "Knowledge Graphs"],
  "featured": false,
  "icon": "GraduationCap",
  "isPrivate": true,
  "githubUrl": "https://github.com/brandonjredmond/ai-tutor",
  "demoUrl": "http://localhost:8000",
  "techStack": [
    {
      "category": "Backend",
      "items": ["Python 3.13", "FastAPI", "UV Package Manager", "Pydantic", "AsyncIO"]
    },
    {
      "category": "AI/Agent System",
      "items": ["Model Context Protocol", "Multi-Agent Orchestration", "Workflow Engine", "WebSocket", "JSON-RPC"]
    },
    {
      "category": "Data & Visualization",
      "items": ["Cytoscape.js", "Knowledge Graphs", "Markdown Generation", "Google Drive API", "Real-time Updates"]
    },
    {
      "category": "Infrastructure",
      "items": ["Docker", "Redis Caching", "PostgreSQL", "Production Monitoring", "API Documentation"]
    }
  ],
  "features": [
    "Multi-source research aggregation from web, YouTube, and academic content",
    "Automatic knowledge graph generation with interactive visualizations",
    "Experience-level adaptive summaries tailored to learner needs",
    "Real-time progress tracking via WebSocket connections",
    "Parallel agent execution for optimal performance",
    "Google Drive integration for automatic backup and sharing",
    "Quality filtering and source credibility ranking",
    "Extensible architecture for adding new specialized agents"
  ],
  "challenges": [
    "Coordinating multiple asynchronous agents with complex dependencies",
    "Building reliable MCP communication across distributed services",
    "Creating knowledge graphs that accurately represent concept relationships",
    "Ensuring content quality while maintaining fast response times",
    "Designing an intuitive interface for complex AI interactions"
  ],
  "outcomes": [
    { "metric": "Response Time", "value": "3-5 min avg" },
    { "metric": "Source Quality", "value": "85% relevance" },
    { "metric": "Agent Efficiency", "value": "5 parallel agents" },
    { "metric": "Knowledge Coverage", "value": "15+ sources/topic" },
    { "metric": "User Satisfaction", "value": "Educational depth" }
  ],
  "educational": [
    "Demonstrates practical MCP implementation for agent coordination",
    "Teaches workflow orchestration patterns for complex tasks",
    "Shows how to build adaptive content generation systems",
    "Illustrates real-time communication patterns with WebSocket",
    "Provides examples of structured data extraction from multiple sources",
    "Explains knowledge graph construction from unstructured content"
  ],
  "globalImpact": {
    "geographicReach": ["United States", "Europe", "Asia", "Latin America"],
    "usersWorldwide": 200,
    "socialImpact": "Democratizes access to personalized education by creating AI-powered learning experiences that adapt to individual needs and learning speeds",
    "environmentalImpact": "Efficient agent orchestration reduces redundant API calls and computational overhead through intelligent caching and parallel processing",
    "accessibilityFeatures": ["Adaptive difficulty levels", "Structured markdown output", "Visual knowledge graphs", "Progressive learning paths"],
    "multilingualSupport": false,
    "economicImpact": "Reduces the cost of personalized tutoring by automating research and content generation, making quality education more accessible",
    "knowledgeSharing": "Open-source implementation with comprehensive documentation enabling educators and developers to build similar systems"
  },
  "localization": {
    "supportedLanguages": ["English"],
    "culturalAdaptations": ["Examples tailored to learner's context", "Culturally neutral content generation"],
    "timeZoneHandling": false,
    "currencySupport": [],
    "regionalCompliance": ["Educational content standards", "Data privacy compliance"]
  },
  "codeSnippets": [
    {
      "title": "Agent Orchestrator with MCP Integration",
      "language": "python",
      "code": "from src.models.data_models import Workflow, WorkflowStep, TopicData\nfrom src.services.mcp_client import MCPClient\nimport asyncio\nfrom typing import Dict, List, Any\n\nclass Orchestrator:\n    \"\"\"Orchestrates multi-agent workflows for research tasks\"\"\"\n    \n    def __init__(self, mcp_client: MCPClient):\n        self.mcp_client = mcp_client\n        self.available_agents = {\n            \"web_search_agent\": \"research\",\n            \"youtube_agent\": \"research\",\n            \"knowledge_graph_agent\": \"analysis\",\n            \"summary_agent\": \"synthesis\",\n            \"drive_agent\": \"storage\"\n        }\n        self.active_workflows = {}\n        \n    async def execute_research_workflow(\n        self, \n        topic: TopicData,\n        progress_callback=None\n    ) -> Dict[str, Any]:\n        \"\"\"Execute complete research workflow with parallel agent coordination\"\"\"\n        \n        workflow_id = str(uuid.uuid4())\n        results = {}\n        \n        try:\n            # Phase 1: Parallel research gathering\n            research_tasks = [\n                self._execute_agent_task(\n                    agent=\"web_search_agent\",\n                    capability=\"search_topic\",\n                    args={\"topic\": topic, \"max_results\": 10}\n                ),\n                self._execute_agent_task(\n                    agent=\"youtube_agent\",\n                    capability=\"search_videos\",\n                    args={\"topic\": topic, \"max_results\": 5}\n                )\n            ]\n            \n            if progress_callback:\n                await progress_callback({\n                    \"step\": \"research_gathering\",\n                    \"progress\": 20,\n                    \"message\": \"Gathering sources from web and video content\"\n                })\n            \n            # Execute parallel research\n            research_results = await asyncio.gather(*research_tasks)\n            results[\"web_sources\"] = research_results[0]\n            results[\"video_sources\"] = research_results[1]\n            \n            # Phase 2: Content extraction\n            all_content = []\n            for source in results[\"web_sources\"]:\n                content = await self._execute_agent_task(\n                    agent=\"web_search_agent\",\n                    capability=\"extract_content\",\n                    args={\"url\": source[\"url\"]}\n                )\n                all_content.append(content)\n            \n            if progress_callback:\n                await progress_callback({\n                    \"step\": \"content_extraction\",\n                    \"progress\": 40,\n                    \"message\": \"Extracting and analyzing content\"\n                })\n            \n            # Phase 3: Knowledge graph construction\n            graph_data = await self._execute_agent_task(\n                agent=\"knowledge_graph_agent\",\n                capability=\"build_graph\",\n                args={\n                    \"content\": all_content,\n                    \"topic\": topic,\n                    \"max_nodes\": 50\n                }\n            )\n            results[\"knowledge_graph\"] = graph_data\n            \n            if progress_callback:\n                await progress_callback({\n                    \"step\": \"knowledge_graph\",\n                    \"progress\": 60,\n                    \"message\": \"Building concept relationships\"\n                })\n            \n            # Phase 4: Summary generation\n            summary = await self._execute_agent_task(\n                agent=\"summary_agent\",\n                capability=\"generate_summary\",\n                args={\n                    \"topic\": topic,\n                    \"sources\": all_content,\n                    \"graph\": graph_data,\n                    \"difficulty\": topic.difficulty\n                }\n            )\n            results[\"summary\"] = summary\n            \n            if progress_callback:\n                await progress_callback({\n                    \"step\": \"summary_generation\",\n                    \"progress\": 80,\n                    \"message\": \"Creating personalized summary\"\n                })\n            \n            # Phase 5: Cloud storage\n            drive_url = await self._execute_agent_task(\n                agent=\"drive_agent\",\n                capability=\"upload_content\",\n                args={\n                    \"content\": summary,\n                    \"filename\": f\"{topic.name}_summary.md\",\n                    \"folder\": \"AI_Tutor_Research\"\n                }\n            )\n            results[\"drive_url\"] = drive_url\n            \n            if progress_callback:\n                await progress_callback({\n                    \"step\": \"completed\",\n                    \"progress\": 100,\n                    \"message\": \"Research completed successfully\"\n                })\n            \n            return results\n            \n        except Exception as e:\n            if progress_callback:\n                await progress_callback({\n                    \"step\": \"error\",\n                    \"progress\": results.get(\"progress\", 0),\n                    \"message\": f\"Error: {str(e)}\"\n                })\n            raise\n    \n    async def _execute_agent_task(\n        self,\n        agent: str,\n        capability: str,\n        args: Dict[str, Any]\n    ) -> Any:\n        \"\"\"Execute a single agent capability via MCP\"\"\"\n        return await self.mcp_client.call_agent_capability(\n            agent_name=agent,\n            capability_name=capability,\n            arguments=args\n        )"
    },
    {
      "title": "Knowledge Graph Builder with Cytoscape Integration",
      "language": "python",
      "code": "from typing import List, Dict, Any\nimport networkx as nx\nfrom collections import defaultdict\nimport re\n\nclass KnowledgeGraphBuilder:\n    \"\"\"Builds interactive knowledge graphs from research content\"\"\"\n    \n    def __init__(self):\n        self.graph = nx.DiGraph()\n        self.concept_importance = defaultdict(float)\n        self.edge_types = {\n            \"prerequisite\": {\"color\": \"#ff6b6b\", \"weight\": 3},\n            \"related_to\": {\"color\": \"#4dabf7\", \"weight\": 2},\n            \"example_of\": {\"color\": \"#51cf66\", \"weight\": 1},\n            \"leads_to\": {\"color\": \"#ffd43b\", \"weight\": 2}\n        }\n    \n    def build_from_content(\n        self,\n        content_sources: List[Dict[str, Any]],\n        topic: str,\n        max_nodes: int = 50\n    ) -> Dict[str, Any]:\n        \"\"\"Build knowledge graph from multiple content sources\"\"\"\n        \n        # Extract concepts from all sources\n        all_concepts = self._extract_concepts(content_sources)\n        \n        # Calculate concept importance based on frequency and context\n        for concept in all_concepts:\n            self.concept_importance[concept[\"name\"]] += concept[\"score\"]\n        \n        # Select top concepts\n        top_concepts = sorted(\n            self.concept_importance.items(),\n            key=lambda x: x[1],\n            reverse=True\n        )[:max_nodes]\n        \n        # Add nodes to graph\n        for concept_name, importance in top_concepts:\n            self.graph.add_node(\n                concept_name,\n                label=concept_name,\n                importance=importance,\n                type=\"concept\"\n            )\n        \n        # Extract and add relationships\n        relationships = self._extract_relationships(\n            content_sources,\n            [c[0] for c in top_concepts]\n        )\n        \n        for rel in relationships:\n            if rel[\"source\"] in self.graph and rel[\"target\"] in self.graph:\n                self.graph.add_edge(\n                    rel[\"source\"],\n                    rel[\"target\"],\n                    type=rel[\"type\"],\n                    strength=rel[\"strength\"]\n                )\n        \n        # Add central topic node\n        self.graph.add_node(\n            topic,\n            label=topic,\n            importance=1.0,\n            type=\"central_topic\"\n        )\n        \n        # Connect top concepts to central topic\n        for concept_name, _ in top_concepts[:5]:\n            self.graph.add_edge(\n                topic,\n                concept_name,\n                type=\"related_to\",\n                strength=0.9\n            )\n        \n        # Convert to Cytoscape format\n        return self._to_cytoscape_format()\n    \n    def _extract_concepts(self, content_sources: List[Dict]) -> List[Dict]:\n        \"\"\"Extract key concepts using NLP techniques\"\"\"\n        concepts = []\n        \n        # Simple concept extraction (in production, use NLP models)\n        concept_patterns = [\n            r'\\b([A-Z][a-z]+ [A-Z][a-z]+)\\b',  # Title case phrases\n            r'\\b(\\w+ learning)\\b',  # Domain-specific patterns\n            r'\\b(\\w+ algorithm)\\b',\n            r'\\b(\\w+ network)\\b'\n        ]\n        \n        for source in content_sources:\n            text = source.get(\"content\", \"\")\n            \n            for pattern in concept_patterns:\n                matches = re.findall(pattern, text, re.IGNORECASE)\n                for match in matches:\n                    concepts.append({\n                        \"name\": match,\n                        \"score\": 1.0,\n                        \"source\": source.get(\"url\", \"\")\n                    })\n        \n        return concepts\n    \n    def _extract_relationships(\n        self,\n        content_sources: List[Dict],\n        concepts: List[str]\n    ) -> List[Dict]:\n        \"\"\"Extract relationships between concepts\"\"\"\n        relationships = []\n        \n        # Relationship patterns\n        patterns = [\n            (r'{} is a prerequisite for {}', 'prerequisite'),\n            (r'{} is related to {}', 'related_to'),\n            (r'{} leads to {}', 'leads_to'),\n            (r'{} is an example of {}', 'example_of')\n        ]\n        \n        for source in content_sources:\n            text = source.get(\"content\", \"\").lower()\n            \n            for concept1 in concepts:\n                for concept2 in concepts:\n                    if concept1 != concept2:\n                        # Check for relationship patterns\n                        for pattern, rel_type in patterns:\n                            search_pattern = pattern.format(\n                                concept1.lower(),\n                                concept2.lower()\n                            )\n                            if search_pattern in text:\n                                relationships.append({\n                                    \"source\": concept1,\n                                    \"target\": concept2,\n                                    \"type\": rel_type,\n                                    \"strength\": 0.8\n                                })\n        \n        return relationships\n    \n    def _to_cytoscape_format(self) -> Dict[str, Any]:\n        \"\"\"Convert NetworkX graph to Cytoscape.js format\"\"\"\n        elements = {\n            \"nodes\": [],\n            \"edges\": []\n        }\n        \n        # Add nodes\n        for node_id, node_data in self.graph.nodes(data=True):\n            elements[\"nodes\"].append({\n                \"data\": {\n                    \"id\": node_id,\n                    \"label\": node_data.get(\"label\", node_id),\n                    \"importance\": node_data.get(\"importance\", 0.5),\n                    \"type\": node_data.get(\"type\", \"concept\")\n                }\n            })\n        \n        # Add edges\n        for source, target, edge_data in self.graph.edges(data=True):\n            edge_type = edge_data.get(\"type\", \"related_to\")\n            elements[\"edges\"].append({\n                \"data\": {\n                    \"id\": f\"{source}-{target}\",\n                    \"source\": source,\n                    \"target\": target,\n                    \"type\": edge_type,\n                    \"strength\": edge_data.get(\"strength\", 0.5),\n                    \"color\": self.edge_types[edge_type][\"color\"],\n                    \"weight\": self.edge_types[edge_type][\"weight\"]\n                }\n            })\n        \n        return {\n            \"elements\": elements,\n            \"style\": self._get_cytoscape_style(),\n            \"layout\": {\"name\": \"cose\", \"animate\": True}\n        }\n    \n    def _get_cytoscape_style(self) -> List[Dict]:\n        \"\"\"Return Cytoscape styling configuration\"\"\"\n        return [\n            {\n                \"selector\": \"node\",\n                \"style\": {\n                    \"label\": \"data(label)\",\n                    \"background-color\": \"#666\",\n                    \"width\": \"mapData(importance, 0, 1, 30, 80)\",\n                    \"height\": \"mapData(importance, 0, 1, 30, 80)\"\n                }\n            },\n            {\n                \"selector\": \"node[type='central_topic']\",\n                \"style\": {\n                    \"background-color\": \"#ff6b6b\",\n                    \"width\": 100,\n                    \"height\": 100\n                }\n            },\n            {\n                \"selector\": \"edge\",\n                \"style\": {\n                    \"width\": \"data(weight)\",\n                    \"line-color\": \"data(color)\",\n                    \"target-arrow-color\": \"data(color)\",\n                    \"target-arrow-shape\": \"triangle\",\n                    \"curve-style\": \"bezier\"\n                }\n            }\n        ]"
    }
  ]
}