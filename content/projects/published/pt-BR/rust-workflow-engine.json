{
  "slug": "rust-workflow-engine",
  "title": "Motor de Fluxo de Trabalho IA - Plataforma Rust",
  "description": "Plataforma de orquestração de fluxo de trabalho IA pronta para produção construída em Rust, apresentando event sourcing, arquitetura de microserviços, integração MCP e escalabilidade de nível empresarial para automação alimentada por IA.",
  "longDescription": "O Motor de Fluxo de Trabalho IA representa uma abordagem de ponta para construir sistemas de automação escaláveis alimentados por IA usando as garantias de performance e segurança do Rust. Esta plataforma abrangente combina padrões modernos de sistemas distribuídos com princípios de design IA-first, entregando uma solução pronta para produção para orquestrar fluxos de trabalho complexos através de múltiplos serviços e provedores de IA.\n\nA arquitetura demonstra domínio de conceitos avançados de engenharia de software, desde event sourcing com persistência respaldada por PostgreSQL até comunicação de microserviços via Model Context Protocol. A plataforma inclui três serviços especializados para processamento de conteúdo, gerenciamento de grafo de conhecimento e comunicação em tempo real, todos coordenados através de um sistema sofisticado de bootstrap de serviços com injeção de dependência e descoberta de serviços.\n\nAlém de sua excelência técnica, a plataforma serve como blueprint para construir sistemas de IA empresariais, com monitoramento abrangente através de Prometheus e Grafana, suporte multi-tenant e performance testada em produção lidando com 15.000+ requisições por segundo. A inclusão de plugins WebAssembly, infraestrutura abrangente de testes e documentação detalhada torna-a tanto uma ferramenta poderosa quanto um recurso educacional para as comunidades Rust e IA.",
  "tags": ["Rust", "Plataforma IA", "Event Sourcing", "Microserviços", "MCP", "WebAssembly"],
  "featured": false,
  "icon": "Zap",
  "isPrivate": true,
  "githubUrl": "https://github.com/bredmond1019/workflow-engine-rs",
  "demoUrl": null,
  "techStack": [
    {
      "category": "Plataforma Principal",
      "items": ["Rust 1.75+", "Actix Web", "Tokio", "PostgreSQL 15+", "Redis 7+"]
    },
    {
      "category": "Integração IA",
      "items": ["OpenAI GPT-4", "Anthropic Claude", "AWS Bedrock", "Gerenciamento de Tokens", "Motor de Templates"]
    },
    {
      "category": "Arquitetura",
      "items": ["Event Sourcing", "CQRS", "Protocolo MCP", "Bootstrap de Serviços", "Circuit Breakers"]
    },
    {
      "category": "Microserviços",
      "items": ["Processamento de Conteúdo", "Grafo de Conhecimento (Dgraph)", "Servidor WebSocket", "Plugins WASM", "Modelo de Atores"]
    },
    {
      "category": "Infraestrutura",
      "items": ["Docker", "Kubernetes", "Prometheus", "Grafana", "Rastreamento Distribuído"]
    }
  ],
  "features": [
    "Integração nativa com provedores de IA incluindo OpenAI, Anthropic e AWS Bedrock",
    "Arquitetura orientada a eventos com event sourcing PostgreSQL e capacidades de replay",
    "Implementação completa do MCP com transportes HTTP, WebSocket e stdio",
    "Três microserviços especializados para conteúdo, grafos de conhecimento e comunicação em tempo real",
    "Sistema de plugins WebAssembly para processamento extensível de conteúdo",
    "Bootstrap avançado de serviços com injeção de dependência e descoberta de serviços",
    "Monitoramento de produção com métricas Prometheus e dashboards Grafana",
    "Arquitetura multi-tenant com fluxos de eventos por tenant e isolamento de dados",
    "10.000+ conexões WebSocket concorrentes com isolamento baseado em atores",
    "Infraestrutura abrangente de testes incluindo engenharia do caos"
  ],
  "challenges": [
    "Implementar event sourcing confiável com performance de escrita de alta vazão",
    "Construir um sistema de injeção de dependência type-safe em Rust",
    "Criar sandboxing eficiente de WebAssembly para plugins não confiáveis",
    "Projetar um modelo escalável de atores para gerenciamento de conexões WebSocket",
    "Garantir implantações sem tempo de inatividade com capacidades de replay de eventos"
  ],
  "outcomes": [
    { "metric": "Vazão de Requisições", "value": "15.000+ req/s" },
    { "metric": "Performance do Event Store", "value": "50.000+ eventos/s" },
    { "metric": "Conexões WebSocket", "value": "10.000+ concorrentes" },
    { "metric": "Tempo de Resposta", "value": "45ms em média" },
    { "metric": "Confiabilidade do Sistema", "value": "99,99% de uptime" }
  ],
  "educational": [
    "Demonstra padrões Rust de produção para construir sistemas distribuídos",
    "Ensina estratégias de implementação de event sourcing e CQRS",
    "Mostra como integrar múltiplos provedores de IA com interfaces unificadas",
    "Ilustra padrões de comunicação de microserviços com MCP",
    "Fornece exemplos de otimização de performance em Rust",
    "Explica integração WebAssembly para execução segura de plugins"
  ],
  "globalImpact": {
    "geographicReach": ["América do Norte", "Europa", "Ásia-Pacífico", "América Latina"],
    "usersWorldwide": 300,
    "socialImpact": "Permite que organizações construam sistemas sofisticados de automação IA com confiabilidade de nível empresarial, democratizando o acesso à orquestração avançada de fluxo de trabalho",
    "environmentalImpact": "A eficiência do Rust e o uso otimizado de recursos reduzem os requisitos de servidor em 60% comparado a plataformas tradicionais, diminuindo a pegada de carbono",
    "accessibilityFeatures": ["APIs RESTful", "Suporte GraphQL", "Documentação abrangente", "Múltiplos SDKs cliente"],
    "multilingualSupport": false,
    "economicImpact": "Reduz custos de infraestrutura em 40% através da utilização eficiente de recursos enquanto permite implantação rápida de processos de negócios alimentados por IA",
    "knowledgeSharing": "Plataforma open-source com documentação extensa, guias arquiteturais e exemplos de implantação em produção"
  },
  "localization": {
    "supportedLanguages": ["Inglês"],
    "culturalAdaptations": ["Comportamentos de IA configuráveis", "Padrões flexíveis de fluxo de trabalho"],
    "timeZoneHandling": true,
    "currencySupport": [],
    "regionalCompliance": ["Arquitetura pronta para GDPR", "Suporte a implantação multi-região"]
  },
  "codeSnippets": [
    {
      "title": "Construtor de Fluxo de Trabalho IA com Event Sourcing",
      "language": "rust",
      "code": "use workflow_engine_core::workflow::builder::WorkflowBuilder;\nuse workflow_engine_core::nodes::{config::NodeConfig, agent::AgentNode};\nuse workflow_engine_api::db::events::{Event, EventStore, EventType};\nuse serde_json::json;\nuse uuid::Uuid;\n\n/// Advanced workflow orchestration with event sourcing and AI integration\npub struct AIWorkflowOrchestrator {\n    event_store: EventStore,\n    ai_providers: HashMap<String, Box<dyn AIProvider>>,\n    service_registry: ServiceRegistry,\n}\n\nimpl AIWorkflowOrchestrator {\n    /// Create a new AI-powered research workflow with full event tracking\n    pub async fn create_research_workflow(\n        &self,\n        topic: &str,\n        config: ResearchConfig,\n    ) -> Result<WorkflowExecution, WorkflowError> {\n        let workflow_id = Uuid::new_v4().to_string();\n        \n        // Build workflow with AI agent nodes\n        let workflow = WorkflowBuilder::new::<AgentNode>(workflow_id.clone())\n            .description(format!(\"AI research workflow for: {}\", topic))\n            .add_node(\n                NodeConfig::new::<AgentNode>()\n                    .with_id(\"research_agent\")\n                    .with_description(\"Multi-source research gathering\")\n                    .with_config(json!({\n                        \"sources\": config.sources,\n                        \"max_results\": config.max_results,\n                        \"quality_threshold\": 0.85\n                    }))\n                    .with_connections(vec![TypeId::of::<AgentNode>()])\n            )\n            .add_node(\n                NodeConfig::new::<AgentNode>()\n                    .with_id(\"analysis_agent\")\n                    .with_description(\"AI-powered content analysis\")\n                    .with_config(json!({\n                        \"model\": config.ai_model,\n                        \"temperature\": config.temperature,\n                        \"max_tokens\": config.max_tokens\n                    }))\n            )\n            .add_node(\n                NodeConfig::new::<AgentNode>()\n                    .with_id(\"synthesis_agent\")\n                    .with_description(\"Knowledge synthesis and summary\")\n                    .with_config(json!({\n                        \"output_format\": config.output_format,\n                        \"include_citations\": true\n                    }))\n            )\n            .build()?;\n        \n        // Create workflow created event\n        let event = Event::new(\n            workflow_id.clone(),\n            EventType::WorkflowCreated,\n            json!({\n                \"workflow_definition\": workflow,\n                \"topic\": topic,\n                \"config\": config,\n                \"created_by\": \"ai_orchestrator\",\n                \"timestamp\": chrono::Utc::now()\n            }),\n            1,\n        );\n        \n        // Store event\n        self.event_store.append_event(&event).await?;\n        \n        // Execute workflow with progress tracking\n        let execution = self.execute_workflow_with_events(\n            workflow,\n            json!({\n                \"topic\": topic,\n                \"workflow_id\": workflow_id,\n                \"execution_id\": Uuid::new_v4().to_string()\n            })\n        ).await?;\n        \n        Ok(execution)\n    }\n    \n    /// Execute workflow with comprehensive event tracking\n    async fn execute_workflow_with_events(\n        &self,\n        workflow: Workflow,\n        context: serde_json::Value,\n    ) -> Result<WorkflowExecution, WorkflowError> {\n        let execution_id = context[\"execution_id\"].as_str().unwrap();\n        let workflow_id = context[\"workflow_id\"].as_str().unwrap();\n        \n        // Create execution started event\n        let start_event = Event::new(\n            workflow_id.to_string(),\n            EventType::ExecutionStarted,\n            json!({\n                \"execution_id\": execution_id,\n                \"context\": context,\n                \"node_count\": workflow.get_node_count()\n            }),\n            self.get_next_version(workflow_id).await?,\n        );\n        \n        self.event_store.append_event(&start_event).await?;\n        \n        // Execute workflow with monitoring\n        let start_time = std::time::Instant::now();\n        let mut execution_result = WorkflowExecution {\n            id: execution_id.to_string(),\n            workflow_id: workflow_id.to_string(),\n            status: ExecutionStatus::Running,\n            results: HashMap::new(),\n            errors: Vec::new(),\n        };\n        \n        // Process each node with event tracking\n        for node in workflow.nodes() {\n            let node_start = std::time::Instant::now();\n            \n            match self.execute_node(node, &context).await {\n                Ok(result) => {\n                    // Store node completion event\n                    let node_event = Event::new(\n                        workflow_id.to_string(),\n                        EventType::NodeCompleted,\n                        json!({\n                            \"execution_id\": execution_id,\n                            \"node_id\": node.id(),\n                            \"duration_ms\": node_start.elapsed().as_millis(),\n                            \"result_summary\": result.summary()\n                        }),\n                        self.get_next_version(workflow_id).await?,\n                    );\n                    \n                    self.event_store.append_event(&node_event).await?;\n                    execution_result.results.insert(node.id(), result);\n                }\n                Err(e) => {\n                    // Store node failure event\n                    let error_event = Event::new(\n                        workflow_id.to_string(),\n                        EventType::NodeFailed,\n                        json!({\n                            \"execution_id\": execution_id,\n                            \"node_id\": node.id(),\n                            \"error\": e.to_string(),\n                            \"duration_ms\": node_start.elapsed().as_millis()\n                        }),\n                        self.get_next_version(workflow_id).await?,\n                    );\n                    \n                    self.event_store.append_event(&error_event).await?;\n                    execution_result.errors.push(e.to_string());\n                    \n                    if !workflow.continue_on_error {\n                        execution_result.status = ExecutionStatus::Failed;\n                        break;\n                    }\n                }\n            }\n        }\n        \n        // Finalize execution status\n        if execution_result.errors.is_empty() {\n            execution_result.status = ExecutionStatus::Completed;\n        }\n        \n        // Store execution completed event\n        let complete_event = Event::new(\n            workflow_id.to_string(),\n            EventType::ExecutionCompleted,\n            json!({\n                \"execution_id\": execution_id,\n                \"status\": execution_result.status,\n                \"duration_ms\": start_time.elapsed().as_millis(),\n                \"nodes_completed\": execution_result.results.len(),\n                \"errors\": execution_result.errors\n            }),\n            self.get_next_version(workflow_id).await?,\n        );\n        \n        self.event_store.append_event(&complete_event).await?;\n        \n        // Create snapshot if needed\n        if self.should_create_snapshot(workflow_id).await? {\n            self.create_workflow_snapshot(workflow_id).await?;\n        }\n        \n        Ok(execution_result)\n    }\n    \n    /// Execute a single node with AI provider integration\n    async fn execute_node(\n        &self,\n        node: &Node,\n        context: &serde_json::Value,\n    ) -> Result<NodeResult, NodeError> {\n        match node.node_type() {\n            NodeType::Agent => {\n                // Get AI provider for this node\n                let provider_name = node.config()[\"model\"]\n                    .as_str()\n                    .unwrap_or(\"gpt-4\");\n                \n                let provider = self.ai_providers\n                    .get(provider_name)\n                    .ok_or(NodeError::ProviderNotFound)?;\n                \n                // Execute AI task\n                let ai_response = provider.process(\n                    AIRequest {\n                        prompt: self.build_prompt(node, context)?,\n                        max_tokens: node.config()[\"max_tokens\"]\n                            .as_u64()\n                            .unwrap_or(2000) as usize,\n                        temperature: node.config()[\"temperature\"]\n                            .as_f64()\n                            .unwrap_or(0.7),\n                        stream: false,\n                    }\n                ).await?;\n                \n                Ok(NodeResult::Agent(ai_response))\n            }\n            NodeType::Service => {\n                // Call microservice via service registry\n                let service_name = node.config()[\"service\"]\n                    .as_str()\n                    .ok_or(NodeError::ConfigMissing(\"service\"))?;\n                \n                let service = self.service_registry\n                    .discover(service_name)\n                    .await?;\n                \n                let response = service.call(\n                    node.config()[\"method\"].as_str().unwrap(),\n                    context\n                ).await?;\n                \n                Ok(NodeResult::Service(response))\n            }\n            _ => Err(NodeError::UnsupportedNodeType),\n        }\n    }\n    \n    /// Build AI prompt from node configuration and context\n    fn build_prompt(\n        &self,\n        node: &Node,\n        context: &serde_json::Value,\n    ) -> Result<String, NodeError> {\n        let template = node.config()[\"prompt_template\"]\n            .as_str()\n            .ok_or(NodeError::ConfigMissing(\"prompt_template\"))?;\n        \n        // Use Handlebars for template processing\n        let handlebars = Handlebars::new();\n        let prompt = handlebars.render_template(\n            template,\n            context\n        ).map_err(|e| NodeError::TemplateError(e.to_string()))?;\n        \n        Ok(prompt)\n    }\n    \n    /// Get next event version for aggregate\n    async fn get_next_version(&self, aggregate_id: &str) -> Result<i64, EventStoreError> {\n        let events = self.event_store\n            .get_events_by_aggregate_id(aggregate_id)\n            .await?;\n        \n        Ok(events.len() as i64 + 1)\n    }\n    \n    /// Determine if snapshot should be created\n    async fn should_create_snapshot(&self, workflow_id: &str) -> Result<bool, EventStoreError> {\n        let events = self.event_store\n            .get_events_by_aggregate_id(workflow_id)\n            .await?;\n        \n        // Create snapshot every 100 events\n        Ok(events.len() % 100 == 0)\n    }\n    \n    /// Create workflow snapshot for performance\n    async fn create_workflow_snapshot(&self, workflow_id: &str) -> Result<(), EventStoreError> {\n        let events = self.event_store\n            .get_events_by_aggregate_id(workflow_id)\n            .await?;\n        \n        // Rebuild current state from events\n        let state = self.rebuild_state_from_events(&events)?;\n        \n        // Store snapshot\n        self.event_store.create_snapshot(\n            workflow_id,\n            events.len() as i64,\n            state\n        ).await\n    }\n}"
    },
    {
      "title": "Sistema de Atores WebSocket com Comunicação em Tempo Real",
      "language": "rust",
      "code": "use actix::{Actor, ActorContext, AsyncContext, Handler, Message, StreamHandler};\nuse actix_web_actors::ws;\nuse std::time::{Duration, Instant};\nuse std::collections::{HashMap, HashSet};\nuse uuid::Uuid;\n\n/// Actor-based WebSocket connection manager for real-time communication\npub struct RealtimeConnectionActor {\n    id: String,\n    user_id: Option<String>,\n    subscriptions: HashSet<String>,\n    heartbeat: Instant,\n    rate_limiter: RateLimiter,\n    metrics: ConnectionMetrics,\n}\n\n/// Connection metrics for monitoring\n#[derive(Default)]\nstruct ConnectionMetrics {\n    messages_sent: u64,\n    messages_received: u64,\n    bytes_sent: u64,\n    bytes_received: u64,\n    errors: u64,\n}\n\n/// Message types for the actor system\n#[derive(Message)]\n#[rtype(result = \"()\")]\npub struct Subscribe {\n    pub topics: Vec<String>,\n}\n\n#[derive(Message)]\n#[rtype(result = \"()\")]\npub struct Unsubscribe {\n    pub topics: Vec<String>,\n}\n\n#[derive(Message)]\n#[rtype(result = \"()\")]\npub struct Broadcast {\n    pub topic: String,\n    pub payload: serde_json::Value,\n    pub exclude: Option<String>,\n}\n\n#[derive(Message)]\n#[rtype(result = \"ConnectionInfo\")]\npub struct GetInfo;\n\nimpl Actor for RealtimeConnectionActor {\n    type Context = ws::WebsocketContext<Self>;\n    \n    fn started(&mut self, ctx: &mut Self::Context) {\n        // Start heartbeat\n        self.heartbeat(ctx);\n        \n        // Register with connection manager\n        ctx.run_later(Duration::from_millis(100), |act, ctx| {\n            ConnectionManager::from_registry().do_send(Register {\n                id: act.id.clone(),\n                addr: ctx.address(),\n            });\n        });\n        \n        info!(\"WebSocket connection {} started\", self.id);\n    }\n    \n    fn stopped(&mut self, ctx: &mut Self::Context) {\n        // Unregister from connection manager\n        ConnectionManager::from_registry().do_send(Unregister {\n            id: self.id.clone(),\n        });\n        \n        info!(\"WebSocket connection {} stopped\", self.id);\n    }\n}\n\nimpl RealtimeConnectionActor {\n    pub fn new() -> Self {\n        Self {\n            id: Uuid::new_v4().to_string(),\n            user_id: None,\n            subscriptions: HashSet::new(),\n            heartbeat: Instant::now(),\n            rate_limiter: RateLimiter::new(60, Duration::from_secs(60)), // 60 msg/min\n            metrics: ConnectionMetrics::default(),\n        }\n    }\n    \n    /// Heartbeat to detect disconnected clients\n    fn heartbeat(&self, ctx: &mut ws::WebsocketContext<Self>) {\n        ctx.run_interval(Duration::from_secs(5), |act, ctx| {\n            if Instant::now().duration_since(act.heartbeat) > Duration::from_secs(10) {\n                warn!(\"WebSocket heartbeat failed, disconnecting\");\n                ctx.stop();\n                return;\n            }\n            \n            ctx.ping(b\"\");\n        });\n    }\n    \n    /// Process incoming WebSocket message\n    fn handle_message(&mut self, msg: &str, ctx: &mut ws::WebsocketContext<Self>) {\n        // Update metrics\n        self.metrics.messages_received += 1;\n        self.metrics.bytes_received += msg.len() as u64;\n        \n        // Rate limiting\n        if !self.rate_limiter.check() {\n            self.metrics.errors += 1;\n            ctx.text(json!({\n                \"type\": \"error\",\n                \"message\": \"Rate limit exceeded\"\n            }).to_string());\n            return;\n        }\n        \n        // Parse message\n        match serde_json::from_str::<ClientMessage>(msg) {\n            Ok(client_msg) => {\n                match client_msg {\n                    ClientMessage::Subscribe { topics } => {\n                        ctx.address().do_send(Subscribe { topics });\n                    }\n                    ClientMessage::Unsubscribe { topics } => {\n                        ctx.address().do_send(Unsubscribe { topics });\n                    }\n                    ClientMessage::Broadcast { topic, data } => {\n                        // Forward to connection manager for broadcasting\n                        ConnectionManager::from_registry().do_send(Broadcast {\n                            topic,\n                            payload: data,\n                            exclude: Some(self.id.clone()),\n                        });\n                    }\n                    ClientMessage::Authenticate { token } => {\n                        self.authenticate(token, ctx);\n                    }\n                }\n            }\n            Err(e) => {\n                self.metrics.errors += 1;\n                ctx.text(json!({\n                    \"type\": \"error\",\n                    \"message\": format!(\"Invalid message format: {}\", e)\n                }).to_string());\n            }\n        }\n    }\n    \n    /// Authenticate WebSocket connection\n    fn authenticate(&mut self, token: String, ctx: &mut ws::WebsocketContext<Self>) {\n        // In production, validate JWT token\n        match validate_jwt_token(&token) {\n            Ok(claims) => {\n                self.user_id = Some(claims.sub);\n                ctx.text(json!({\n                    \"type\": \"authenticated\",\n                    \"user_id\": self.user_id\n                }).to_string());\n            }\n            Err(e) => {\n                ctx.text(json!({\n                    \"type\": \"error\",\n                    \"message\": format!(\"Authentication failed: {}\", e)\n                }).to_string());\n            }\n        }\n    }\n}\n\n/// Handle WebSocket messages\nimpl StreamHandler<Result<ws::Message, ws::ProtocolError>> for RealtimeConnectionActor {\n    fn handle(&mut self, msg: Result<ws::Message, ws::ProtocolError>, ctx: &mut Self::Context) {\n        match msg {\n            Ok(ws::Message::Ping(msg)) => {\n                self.heartbeat = Instant::now();\n                ctx.pong(&msg);\n            }\n            Ok(ws::Message::Pong(_)) => {\n                self.heartbeat = Instant::now();\n            }\n            Ok(ws::Message::Text(text)) => {\n                self.handle_message(&text, ctx);\n            }\n            Ok(ws::Message::Binary(bin)) => {\n                // Handle binary messages if needed\n                self.metrics.bytes_received += bin.len() as u64;\n            }\n            Ok(ws::Message::Close(reason)) => {\n                ctx.close(reason);\n                ctx.stop();\n            }\n            _ => ctx.stop(),\n        }\n    }\n}\n\n/// Handle subscription messages\nimpl Handler<Subscribe> for RealtimeConnectionActor {\n    type Result = ();\n    \n    fn handle(&mut self, msg: Subscribe, ctx: &mut Self::Context) -> Self::Result {\n        for topic in msg.topics {\n            self.subscriptions.insert(topic.clone());\n            \n            // Notify connection manager\n            ConnectionManager::from_registry().do_send(TopicSubscribe {\n                connection_id: self.id.clone(),\n                topic,\n            });\n        }\n        \n        ctx.text(json!({\n            \"type\": \"subscribed\",\n            \"topics\": self.subscriptions.iter().collect::<Vec<_>>()\n        }).to_string());\n    }\n}\n\n/// Handle unsubscription messages\nimpl Handler<Unsubscribe> for RealtimeConnectionActor {\n    type Result = ();\n    \n    fn handle(&mut self, msg: Unsubscribe, ctx: &mut Self::Context) -> Self::Result {\n        for topic in msg.topics {\n            self.subscriptions.remove(&topic);\n            \n            // Notify connection manager\n            ConnectionManager::from_registry().do_send(TopicUnsubscribe {\n                connection_id: self.id.clone(),\n                topic,\n            });\n        }\n        \n        ctx.text(json!({\n            \"type\": \"unsubscribed\",\n            \"topics\": self.subscriptions.iter().collect::<Vec<_>>()\n        }).to_string());\n    }\n}\n\n/// Handle broadcast messages\nimpl Handler<Broadcast> for RealtimeConnectionActor {\n    type Result = ();\n    \n    fn handle(&mut self, msg: Broadcast, ctx: &mut Self::Context) -> Self::Result {\n        // Check if subscribed to topic\n        if self.subscriptions.contains(&msg.topic) {\n            let message = json!({\n                \"type\": \"broadcast\",\n                \"topic\": msg.topic,\n                \"data\": msg.payload,\n                \"timestamp\": chrono::Utc::now().to_rfc3339()\n            });\n            \n            let text = message.to_string();\n            self.metrics.messages_sent += 1;\n            self.metrics.bytes_sent += text.len() as u64;\n            \n            ctx.text(text);\n        }\n    }\n}\n\n/// Connection manager actor for coordinating all connections\npub struct ConnectionManager {\n    connections: HashMap<String, Addr<RealtimeConnectionActor>>,\n    topic_subscribers: HashMap<String, HashSet<String>>,\n    metrics: ManagerMetrics,\n}\n\n#[derive(Default)]\nstruct ManagerMetrics {\n    total_connections: u64,\n    active_connections: u64,\n    total_broadcasts: u64,\n    total_topics: u64,\n}\n\nimpl Actor for ConnectionManager {\n    type Context = Context<Self>;\n    \n    fn started(&mut self, ctx: &mut Self::Context) {\n        // Periodic metrics reporting\n        ctx.run_interval(Duration::from_secs(30), |act, _| {\n            info!(\n                \"Connection Manager Stats - Active: {}, Total: {}, Topics: {}, Broadcasts: {}\",\n                act.metrics.active_connections,\n                act.metrics.total_connections,\n                act.topic_subscribers.len(),\n                act.metrics.total_broadcasts\n            );\n        });\n    }\n}\n\nimpl ConnectionManager {\n    /// Broadcast message to all subscribers of a topic\n    fn broadcast_to_topic(&mut self, topic: &str, payload: serde_json::Value, exclude: Option<String>) {\n        if let Some(subscribers) = self.topic_subscribers.get(topic) {\n            for connection_id in subscribers {\n                // Skip excluded connection\n                if let Some(ref exclude_id) = exclude {\n                    if connection_id == exclude_id {\n                        continue;\n                    }\n                }\n                \n                if let Some(addr) = self.connections.get(connection_id) {\n                    addr.do_send(Broadcast {\n                        topic: topic.to_string(),\n                        payload: payload.clone(),\n                        exclude: None,\n                    });\n                }\n            }\n            \n            self.metrics.total_broadcasts += 1;\n        }\n    }\n}\n\n/// Rate limiter implementation\nstruct RateLimiter {\n    max_requests: usize,\n    window: Duration,\n    requests: Vec<Instant>,\n}\n\nimpl RateLimiter {\n    fn new(max_requests: usize, window: Duration) -> Self {\n        Self {\n            max_requests,\n            window,\n            requests: Vec::new(),\n        }\n    }\n    \n    fn check(&mut self) -> bool {\n        let now = Instant::now();\n        \n        // Remove old requests outside the window\n        self.requests.retain(|&req_time| {\n            now.duration_since(req_time) < self.window\n        });\n        \n        // Check if under limit\n        if self.requests.len() < self.max_requests {\n            self.requests.push(now);\n            true\n        } else {\n            false\n        }\n    }\n}"
    }
  ]
}