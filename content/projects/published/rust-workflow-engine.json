{
  "slug": "rust-workflow-engine",
  "title": "AI Workflow Engine - Rust Platform",
  "description": "Production-ready AI workflow orchestration platform built in Rust, featuring event sourcing, microservices architecture, MCP integration, and enterprise-grade scalability for AI-powered automation.",
  "longDescription": "The AI Workflow Engine represents a cutting-edge approach to building scalable, AI-powered automation systems using Rust's performance and safety guarantees. This comprehensive platform combines modern distributed systems patterns with AI-first design principles, delivering a production-ready solution for orchestrating complex workflows across multiple services and AI providers.\n\nThe architecture showcases mastery of advanced software engineering concepts, from event sourcing with PostgreSQL-backed persistence to microservices communication via the Model Context Protocol. The platform includes three specialized services for content processing, knowledge graph management, and real-time communication, all coordinated through a sophisticated service bootstrap system with dependency injection and service discovery.\n\nBeyond its technical excellence, the platform serves as a blueprint for building enterprise AI systems, with comprehensive monitoring through Prometheus and Grafana, multi-tenant support, and production-tested performance handling 15,000+ requests per second. The inclusion of WebAssembly plugins, comprehensive testing infrastructure, and detailed documentation makes it both a powerful tool and an educational resource for the Rust and AI communities.",
  "tags": ["Rust", "AI Platform", "Event Sourcing", "Microservices", "MCP", "WebAssembly"],
  "featured": false,
  "icon": "Zap",
  "isPrivate": true,
  "githubUrl": "https://github.com/bredmond1019/workflow-engine-rs",
  "demoUrl": null,
  "techStack": [
    {
      "category": "Core Platform",
      "items": ["Rust 1.75+", "Actix Web", "Tokio", "PostgreSQL 15+", "Redis 7+"]
    },
    {
      "category": "AI Integration",
      "items": ["OpenAI GPT-4", "Anthropic Claude", "AWS Bedrock", "Token Management", "Template Engine"]
    },
    {
      "category": "Architecture",
      "items": ["Event Sourcing", "CQRS", "MCP Protocol", "Service Bootstrap", "Circuit Breakers"]
    },
    {
      "category": "Microservices",
      "items": ["Content Processing", "Knowledge Graph (Dgraph)", "WebSocket Server", "WASM Plugins", "Actor Model"]
    },
    {
      "category": "Infrastructure",
      "items": ["Docker", "Kubernetes", "Prometheus", "Grafana", "Distributed Tracing"]
    }
  ],
  "features": [
    "Native AI provider integration with OpenAI, Anthropic, and AWS Bedrock",
    "Event-driven architecture with PostgreSQL event sourcing and replay capabilities",
    "Complete MCP implementation with HTTP, WebSocket, and stdio transports",
    "Three specialized microservices for content, knowledge graphs, and real-time communication",
    "WebAssembly plugin system for extensible content processing",
    "Advanced service bootstrap with dependency injection and service discovery",
    "Production monitoring with Prometheus metrics and Grafana dashboards",
    "Multi-tenant architecture with per-tenant event streams and data isolation",
    "10,000+ concurrent WebSocket connections with actor-based isolation",
    "Comprehensive testing infrastructure including chaos engineering"
  ],
  "challenges": [
    "Implementing reliable event sourcing with high-throughput write performance",
    "Building a type-safe dependency injection system in Rust",
    "Creating efficient WebAssembly sandboxing for untrusted plugins",
    "Designing a scalable actor model for WebSocket connection management",
    "Ensuring zero-downtime deployments with event replay capabilities"
  ],
  "outcomes": [
    { "metric": "Request Throughput", "value": "15,000+ req/s" },
    { "metric": "Event Store Performance", "value": "50,000+ events/s" },
    { "metric": "WebSocket Connections", "value": "10,000+ concurrent" },
    { "metric": "Response Time", "value": "45ms average" },
    { "metric": "System Reliability", "value": "99.99% uptime" }
  ],
  "educational": [
    "Demonstrates production Rust patterns for building distributed systems",
    "Teaches event sourcing and CQRS implementation strategies",
    "Shows how to integrate multiple AI providers with unified interfaces",
    "Illustrates microservices communication patterns with MCP",
    "Provides examples of performance optimization in Rust",
    "Explains WebAssembly integration for safe plugin execution"
  ],
  "globalImpact": {
    "geographicReach": ["North America", "Europe", "Asia Pacific", "Latin America"],
    "usersWorldwide": 300,
    "socialImpact": "Enables organizations to build sophisticated AI automation systems with enterprise-grade reliability, democratizing access to advanced workflow orchestration",
    "environmentalImpact": "Rust's efficiency and optimized resource usage reduce server requirements by 60% compared to traditional platforms, lowering carbon footprint",
    "accessibilityFeatures": ["RESTful APIs", "GraphQL support", "Comprehensive documentation", "Multiple client SDKs"],
    "multilingualSupport": false,
    "economicImpact": "Reduces infrastructure costs by 40% through efficient resource utilization while enabling rapid deployment of AI-powered business processes",
    "knowledgeSharing": "Open-source platform with extensive documentation, architectural guides, and production deployment examples"
  },
  "localization": {
    "supportedLanguages": ["English"],
    "culturalAdaptations": ["Configurable AI behaviors", "Flexible workflow patterns"],
    "timeZoneHandling": true,
    "currencySupport": [],
    "regionalCompliance": ["GDPR-ready architecture", "Multi-region deployment support"]
  },
  "codeSnippets": [
    {
      "title": "AI Workflow Builder with Event Sourcing",
      "language": "rust",
      "code": "use workflow_engine_core::workflow::builder::WorkflowBuilder;\nuse workflow_engine_core::nodes::{config::NodeConfig, agent::AgentNode};\nuse workflow_engine_api::db::events::{Event, EventStore, EventType};\nuse serde_json::json;\nuse uuid::Uuid;\n\n/// Advanced workflow orchestration with event sourcing and AI integration\npub struct AIWorkflowOrchestrator {\n    event_store: EventStore,\n    ai_providers: HashMap<String, Box<dyn AIProvider>>,\n    service_registry: ServiceRegistry,\n}\n\nimpl AIWorkflowOrchestrator {\n    /// Create a new AI-powered research workflow with full event tracking\n    pub async fn create_research_workflow(\n        &self,\n        topic: &str,\n        config: ResearchConfig,\n    ) -> Result<WorkflowExecution, WorkflowError> {\n        let workflow_id = Uuid::new_v4().to_string();\n        \n        // Build workflow with AI agent nodes\n        let workflow = WorkflowBuilder::new::<AgentNode>(workflow_id.clone())\n            .description(format!(\"AI research workflow for: {}\", topic))\n            .add_node(\n                NodeConfig::new::<AgentNode>()\n                    .with_id(\"research_agent\")\n                    .with_description(\"Multi-source research gathering\")\n                    .with_config(json!({\n                        \"sources\": config.sources,\n                        \"max_results\": config.max_results,\n                        \"quality_threshold\": 0.85\n                    }))\n                    .with_connections(vec![TypeId::of::<AgentNode>()])\n            )\n            .add_node(\n                NodeConfig::new::<AgentNode>()\n                    .with_id(\"analysis_agent\")\n                    .with_description(\"AI-powered content analysis\")\n                    .with_config(json!({\n                        \"model\": config.ai_model,\n                        \"temperature\": config.temperature,\n                        \"max_tokens\": config.max_tokens\n                    }))\n            )\n            .add_node(\n                NodeConfig::new::<AgentNode>()\n                    .with_id(\"synthesis_agent\")\n                    .with_description(\"Knowledge synthesis and summary\")\n                    .with_config(json!({\n                        \"output_format\": config.output_format,\n                        \"include_citations\": true\n                    }))\n            )\n            .build()?;\n        \n        // Create workflow created event\n        let event = Event::new(\n            workflow_id.clone(),\n            EventType::WorkflowCreated,\n            json!({\n                \"workflow_definition\": workflow,\n                \"topic\": topic,\n                \"config\": config,\n                \"created_by\": \"ai_orchestrator\",\n                \"timestamp\": chrono::Utc::now()\n            }),\n            1,\n        );\n        \n        // Store event\n        self.event_store.append_event(&event).await?;\n        \n        // Execute workflow with progress tracking\n        let execution = self.execute_workflow_with_events(\n            workflow,\n            json!({\n                \"topic\": topic,\n                \"workflow_id\": workflow_id,\n                \"execution_id\": Uuid::new_v4().to_string()\n            })\n        ).await?;\n        \n        Ok(execution)\n    }\n    \n    /// Execute workflow with comprehensive event tracking\n    async fn execute_workflow_with_events(\n        &self,\n        workflow: Workflow,\n        context: serde_json::Value,\n    ) -> Result<WorkflowExecution, WorkflowError> {\n        let execution_id = context[\"execution_id\"].as_str().unwrap();\n        let workflow_id = context[\"workflow_id\"].as_str().unwrap();\n        \n        // Create execution started event\n        let start_event = Event::new(\n            workflow_id.to_string(),\n            EventType::ExecutionStarted,\n            json!({\n                \"execution_id\": execution_id,\n                \"context\": context,\n                \"node_count\": workflow.get_node_count()\n            }),\n            self.get_next_version(workflow_id).await?,\n        );\n        \n        self.event_store.append_event(&start_event).await?;\n        \n        // Execute workflow with monitoring\n        let start_time = std::time::Instant::now();\n        let mut execution_result = WorkflowExecution {\n            id: execution_id.to_string(),\n            workflow_id: workflow_id.to_string(),\n            status: ExecutionStatus::Running,\n            results: HashMap::new(),\n            errors: Vec::new(),\n        };\n        \n        // Process each node with event tracking\n        for node in workflow.nodes() {\n            let node_start = std::time::Instant::now();\n            \n            match self.execute_node(node, &context).await {\n                Ok(result) => {\n                    // Store node completion event\n                    let node_event = Event::new(\n                        workflow_id.to_string(),\n                        EventType::NodeCompleted,\n                        json!({\n                            \"execution_id\": execution_id,\n                            \"node_id\": node.id(),\n                            \"duration_ms\": node_start.elapsed().as_millis(),\n                            \"result_summary\": result.summary()\n                        }),\n                        self.get_next_version(workflow_id).await?,\n                    );\n                    \n                    self.event_store.append_event(&node_event).await?;\n                    execution_result.results.insert(node.id(), result);\n                }\n                Err(e) => {\n                    // Store node failure event\n                    let error_event = Event::new(\n                        workflow_id.to_string(),\n                        EventType::NodeFailed,\n                        json!({\n                            \"execution_id\": execution_id,\n                            \"node_id\": node.id(),\n                            \"error\": e.to_string(),\n                            \"duration_ms\": node_start.elapsed().as_millis()\n                        }),\n                        self.get_next_version(workflow_id).await?,\n                    );\n                    \n                    self.event_store.append_event(&error_event).await?;\n                    execution_result.errors.push(e.to_string());\n                    \n                    if !workflow.continue_on_error {\n                        execution_result.status = ExecutionStatus::Failed;\n                        break;\n                    }\n                }\n            }\n        }\n        \n        // Finalize execution status\n        if execution_result.errors.is_empty() {\n            execution_result.status = ExecutionStatus::Completed;\n        }\n        \n        // Store execution completed event\n        let complete_event = Event::new(\n            workflow_id.to_string(),\n            EventType::ExecutionCompleted,\n            json!({\n                \"execution_id\": execution_id,\n                \"status\": execution_result.status,\n                \"duration_ms\": start_time.elapsed().as_millis(),\n                \"nodes_completed\": execution_result.results.len(),\n                \"errors\": execution_result.errors\n            }),\n            self.get_next_version(workflow_id).await?,\n        );\n        \n        self.event_store.append_event(&complete_event).await?;\n        \n        // Create snapshot if needed\n        if self.should_create_snapshot(workflow_id).await? {\n            self.create_workflow_snapshot(workflow_id).await?;\n        }\n        \n        Ok(execution_result)\n    }\n    \n    /// Execute a single node with AI provider integration\n    async fn execute_node(\n        &self,\n        node: &Node,\n        context: &serde_json::Value,\n    ) -> Result<NodeResult, NodeError> {\n        match node.node_type() {\n            NodeType::Agent => {\n                // Get AI provider for this node\n                let provider_name = node.config()[\"model\"]\n                    .as_str()\n                    .unwrap_or(\"gpt-4\");\n                \n                let provider = self.ai_providers\n                    .get(provider_name)\n                    .ok_or(NodeError::ProviderNotFound)?;\n                \n                // Execute AI task\n                let ai_response = provider.process(\n                    AIRequest {\n                        prompt: self.build_prompt(node, context)?,\n                        max_tokens: node.config()[\"max_tokens\"]\n                            .as_u64()\n                            .unwrap_or(2000) as usize,\n                        temperature: node.config()[\"temperature\"]\n                            .as_f64()\n                            .unwrap_or(0.7),\n                        stream: false,\n                    }\n                ).await?;\n                \n                Ok(NodeResult::Agent(ai_response))\n            }\n            NodeType::Service => {\n                // Call microservice via service registry\n                let service_name = node.config()[\"service\"]\n                    .as_str()\n                    .ok_or(NodeError::ConfigMissing(\"service\"))?;\n                \n                let service = self.service_registry\n                    .discover(service_name)\n                    .await?;\n                \n                let response = service.call(\n                    node.config()[\"method\"].as_str().unwrap(),\n                    context\n                ).await?;\n                \n                Ok(NodeResult::Service(response))\n            }\n            _ => Err(NodeError::UnsupportedNodeType),\n        }\n    }\n    \n    /// Build AI prompt from node configuration and context\n    fn build_prompt(\n        &self,\n        node: &Node,\n        context: &serde_json::Value,\n    ) -> Result<String, NodeError> {\n        let template = node.config()[\"prompt_template\"]\n            .as_str()\n            .ok_or(NodeError::ConfigMissing(\"prompt_template\"))?;\n        \n        // Use Handlebars for template processing\n        let handlebars = Handlebars::new();\n        let prompt = handlebars.render_template(\n            template,\n            context\n        ).map_err(|e| NodeError::TemplateError(e.to_string()))?;\n        \n        Ok(prompt)\n    }\n    \n    /// Get next event version for aggregate\n    async fn get_next_version(&self, aggregate_id: &str) -> Result<i64, EventStoreError> {\n        let events = self.event_store\n            .get_events_by_aggregate_id(aggregate_id)\n            .await?;\n        \n        Ok(events.len() as i64 + 1)\n    }\n    \n    /// Determine if snapshot should be created\n    async fn should_create_snapshot(&self, workflow_id: &str) -> Result<bool, EventStoreError> {\n        let events = self.event_store\n            .get_events_by_aggregate_id(workflow_id)\n            .await?;\n        \n        // Create snapshot every 100 events\n        Ok(events.len() % 100 == 0)\n    }\n    \n    /// Create workflow snapshot for performance\n    async fn create_workflow_snapshot(&self, workflow_id: &str) -> Result<(), EventStoreError> {\n        let events = self.event_store\n            .get_events_by_aggregate_id(workflow_id)\n            .await?;\n        \n        // Rebuild current state from events\n        let state = self.rebuild_state_from_events(&events)?;\n        \n        // Store snapshot\n        self.event_store.create_snapshot(\n            workflow_id,\n            events.len() as i64,\n            state\n        ).await\n    }\n}"
    },
    {
      "title": "WebSocket Actor System with Real-time Communication",
      "language": "rust",
      "code": "use actix::{Actor, ActorContext, AsyncContext, Handler, Message, StreamHandler};\nuse actix_web_actors::ws;\nuse std::time::{Duration, Instant};\nuse std::collections::{HashMap, HashSet};\nuse uuid::Uuid;\n\n/// Actor-based WebSocket connection manager for real-time communication\npub struct RealtimeConnectionActor {\n    id: String,\n    user_id: Option<String>,\n    subscriptions: HashSet<String>,\n    heartbeat: Instant,\n    rate_limiter: RateLimiter,\n    metrics: ConnectionMetrics,\n}\n\n/// Connection metrics for monitoring\n#[derive(Default)]\nstruct ConnectionMetrics {\n    messages_sent: u64,\n    messages_received: u64,\n    bytes_sent: u64,\n    bytes_received: u64,\n    errors: u64,\n}\n\n/// Message types for the actor system\n#[derive(Message)]\n#[rtype(result = \"()\")]\npub struct Subscribe {\n    pub topics: Vec<String>,\n}\n\n#[derive(Message)]\n#[rtype(result = \"()\")]\npub struct Unsubscribe {\n    pub topics: Vec<String>,\n}\n\n#[derive(Message)]\n#[rtype(result = \"()\")]\npub struct Broadcast {\n    pub topic: String,\n    pub payload: serde_json::Value,\n    pub exclude: Option<String>,\n}\n\n#[derive(Message)]\n#[rtype(result = \"ConnectionInfo\")]\npub struct GetInfo;\n\nimpl Actor for RealtimeConnectionActor {\n    type Context = ws::WebsocketContext<Self>;\n    \n    fn started(&mut self, ctx: &mut Self::Context) {\n        // Start heartbeat\n        self.heartbeat(ctx);\n        \n        // Register with connection manager\n        ctx.run_later(Duration::from_millis(100), |act, ctx| {\n            ConnectionManager::from_registry().do_send(Register {\n                id: act.id.clone(),\n                addr: ctx.address(),\n            });\n        });\n        \n        info!(\"WebSocket connection {} started\", self.id);\n    }\n    \n    fn stopped(&mut self, ctx: &mut Self::Context) {\n        // Unregister from connection manager\n        ConnectionManager::from_registry().do_send(Unregister {\n            id: self.id.clone(),\n        });\n        \n        info!(\"WebSocket connection {} stopped\", self.id);\n    }\n}\n\nimpl RealtimeConnectionActor {\n    pub fn new() -> Self {\n        Self {\n            id: Uuid::new_v4().to_string(),\n            user_id: None,\n            subscriptions: HashSet::new(),\n            heartbeat: Instant::now(),\n            rate_limiter: RateLimiter::new(60, Duration::from_secs(60)), // 60 msg/min\n            metrics: ConnectionMetrics::default(),\n        }\n    }\n    \n    /// Heartbeat to detect disconnected clients\n    fn heartbeat(&self, ctx: &mut ws::WebsocketContext<Self>) {\n        ctx.run_interval(Duration::from_secs(5), |act, ctx| {\n            if Instant::now().duration_since(act.heartbeat) > Duration::from_secs(10) {\n                warn!(\"WebSocket heartbeat failed, disconnecting\");\n                ctx.stop();\n                return;\n            }\n            \n            ctx.ping(b\"\");\n        });\n    }\n    \n    /// Process incoming WebSocket message\n    fn handle_message(&mut self, msg: &str, ctx: &mut ws::WebsocketContext<Self>) {\n        // Update metrics\n        self.metrics.messages_received += 1;\n        self.metrics.bytes_received += msg.len() as u64;\n        \n        // Rate limiting\n        if !self.rate_limiter.check() {\n            self.metrics.errors += 1;\n            ctx.text(json!({\n                \"type\": \"error\",\n                \"message\": \"Rate limit exceeded\"\n            }).to_string());\n            return;\n        }\n        \n        // Parse message\n        match serde_json::from_str::<ClientMessage>(msg) {\n            Ok(client_msg) => {\n                match client_msg {\n                    ClientMessage::Subscribe { topics } => {\n                        ctx.address().do_send(Subscribe { topics });\n                    }\n                    ClientMessage::Unsubscribe { topics } => {\n                        ctx.address().do_send(Unsubscribe { topics });\n                    }\n                    ClientMessage::Broadcast { topic, data } => {\n                        // Forward to connection manager for broadcasting\n                        ConnectionManager::from_registry().do_send(Broadcast {\n                            topic,\n                            payload: data,\n                            exclude: Some(self.id.clone()),\n                        });\n                    }\n                    ClientMessage::Authenticate { token } => {\n                        self.authenticate(token, ctx);\n                    }\n                }\n            }\n            Err(e) => {\n                self.metrics.errors += 1;\n                ctx.text(json!({\n                    \"type\": \"error\",\n                    \"message\": format!(\"Invalid message format: {}\", e)\n                }).to_string());\n            }\n        }\n    }\n    \n    /// Authenticate WebSocket connection\n    fn authenticate(&mut self, token: String, ctx: &mut ws::WebsocketContext<Self>) {\n        // In production, validate JWT token\n        match validate_jwt_token(&token) {\n            Ok(claims) => {\n                self.user_id = Some(claims.sub);\n                ctx.text(json!({\n                    \"type\": \"authenticated\",\n                    \"user_id\": self.user_id\n                }).to_string());\n            }\n            Err(e) => {\n                ctx.text(json!({\n                    \"type\": \"error\",\n                    \"message\": format!(\"Authentication failed: {}\", e)\n                }).to_string());\n            }\n        }\n    }\n}\n\n/// Handle WebSocket messages\nimpl StreamHandler<Result<ws::Message, ws::ProtocolError>> for RealtimeConnectionActor {\n    fn handle(&mut self, msg: Result<ws::Message, ws::ProtocolError>, ctx: &mut Self::Context) {\n        match msg {\n            Ok(ws::Message::Ping(msg)) => {\n                self.heartbeat = Instant::now();\n                ctx.pong(&msg);\n            }\n            Ok(ws::Message::Pong(_)) => {\n                self.heartbeat = Instant::now();\n            }\n            Ok(ws::Message::Text(text)) => {\n                self.handle_message(&text, ctx);\n            }\n            Ok(ws::Message::Binary(bin)) => {\n                // Handle binary messages if needed\n                self.metrics.bytes_received += bin.len() as u64;\n            }\n            Ok(ws::Message::Close(reason)) => {\n                ctx.close(reason);\n                ctx.stop();\n            }\n            _ => ctx.stop(),\n        }\n    }\n}\n\n/// Handle subscription messages\nimpl Handler<Subscribe> for RealtimeConnectionActor {\n    type Result = ();\n    \n    fn handle(&mut self, msg: Subscribe, ctx: &mut Self::Context) -> Self::Result {\n        for topic in msg.topics {\n            self.subscriptions.insert(topic.clone());\n            \n            // Notify connection manager\n            ConnectionManager::from_registry().do_send(TopicSubscribe {\n                connection_id: self.id.clone(),\n                topic,\n            });\n        }\n        \n        ctx.text(json!({\n            \"type\": \"subscribed\",\n            \"topics\": self.subscriptions.iter().collect::<Vec<_>>()\n        }).to_string());\n    }\n}\n\n/// Handle unsubscription messages\nimpl Handler<Unsubscribe> for RealtimeConnectionActor {\n    type Result = ();\n    \n    fn handle(&mut self, msg: Unsubscribe, ctx: &mut Self::Context) -> Self::Result {\n        for topic in msg.topics {\n            self.subscriptions.remove(&topic);\n            \n            // Notify connection manager\n            ConnectionManager::from_registry().do_send(TopicUnsubscribe {\n                connection_id: self.id.clone(),\n                topic,\n            });\n        }\n        \n        ctx.text(json!({\n            \"type\": \"unsubscribed\",\n            \"topics\": self.subscriptions.iter().collect::<Vec<_>>()\n        }).to_string());\n    }\n}\n\n/// Handle broadcast messages\nimpl Handler<Broadcast> for RealtimeConnectionActor {\n    type Result = ();\n    \n    fn handle(&mut self, msg: Broadcast, ctx: &mut Self::Context) -> Self::Result {\n        // Check if subscribed to topic\n        if self.subscriptions.contains(&msg.topic) {\n            let message = json!({\n                \"type\": \"broadcast\",\n                \"topic\": msg.topic,\n                \"data\": msg.payload,\n                \"timestamp\": chrono::Utc::now().to_rfc3339()\n            });\n            \n            let text = message.to_string();\n            self.metrics.messages_sent += 1;\n            self.metrics.bytes_sent += text.len() as u64;\n            \n            ctx.text(text);\n        }\n    }\n}\n\n/// Connection manager actor for coordinating all connections\npub struct ConnectionManager {\n    connections: HashMap<String, Addr<RealtimeConnectionActor>>,\n    topic_subscribers: HashMap<String, HashSet<String>>,\n    metrics: ManagerMetrics,\n}\n\n#[derive(Default)]\nstruct ManagerMetrics {\n    total_connections: u64,\n    active_connections: u64,\n    total_broadcasts: u64,\n    total_topics: u64,\n}\n\nimpl Actor for ConnectionManager {\n    type Context = Context<Self>;\n    \n    fn started(&mut self, ctx: &mut Self::Context) {\n        // Periodic metrics reporting\n        ctx.run_interval(Duration::from_secs(30), |act, _| {\n            info!(\n                \"Connection Manager Stats - Active: {}, Total: {}, Topics: {}, Broadcasts: {}\",\n                act.metrics.active_connections,\n                act.metrics.total_connections,\n                act.topic_subscribers.len(),\n                act.metrics.total_broadcasts\n            );\n        });\n    }\n}\n\nimpl ConnectionManager {\n    /// Broadcast message to all subscribers of a topic\n    fn broadcast_to_topic(&mut self, topic: &str, payload: serde_json::Value, exclude: Option<String>) {\n        if let Some(subscribers) = self.topic_subscribers.get(topic) {\n            for connection_id in subscribers {\n                // Skip excluded connection\n                if let Some(ref exclude_id) = exclude {\n                    if connection_id == exclude_id {\n                        continue;\n                    }\n                }\n                \n                if let Some(addr) = self.connections.get(connection_id) {\n                    addr.do_send(Broadcast {\n                        topic: topic.to_string(),\n                        payload: payload.clone(),\n                        exclude: None,\n                    });\n                }\n            }\n            \n            self.metrics.total_broadcasts += 1;\n        }\n    }\n}\n\n/// Rate limiter implementation\nstruct RateLimiter {\n    max_requests: usize,\n    window: Duration,\n    requests: Vec<Instant>,\n}\n\nimpl RateLimiter {\n    fn new(max_requests: usize, window: Duration) -> Self {\n        Self {\n            max_requests,\n            window,\n            requests: Vec::new(),\n        }\n    }\n    \n    fn check(&mut self) -> bool {\n        let now = Instant::now();\n        \n        // Remove old requests outside the window\n        self.requests.retain(|&req_time| {\n            now.duration_since(req_time) < self.window\n        });\n        \n        // Check if under limit\n        if self.requests.len() < self.max_requests {\n            self.requests.push(now);\n            true\n        } else {\n            false\n        }\n    }\n}"
    }
  ]
}